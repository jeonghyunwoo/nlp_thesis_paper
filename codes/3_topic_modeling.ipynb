{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    " \n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    " \n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    " \n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA 접근방식  \n",
    "- 각 도큐먼트를 특정 비율의 토픽의 집합으로 가정  \n",
    "- 각 토픽은 각 키워드의 일정 비율로 구성  \n",
    "- 토픽은 일반적으로 표현되는 지배적인 키워드의 모음  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "enws = pd.read_csv('data/economy_news_전처리.csv',usecols=['id','dat','title','text','press'],parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "enws.dat = pd.to_datetime(enws.dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "enws['ymon'] = enws.dat.dt.strftime('%Y%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tridx = enws.loc[enws.dat<'2020-03-01'].id.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27460"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tridx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\decorators.py:68: DeprecationWarning: `formatargspec` is deprecated since Python 3.5. Use `signature` and the `Signature` object directly\n",
      "  regargs, varargs, varkwargs, defaults, formatvalue=lambda value: \"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\lm\\counter.py:15: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence, defaultdict\n"
     ]
    }
   ],
   "source": [
    "# 불용어 준비\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# 이메일 주소와 줄바꿈 문자 제거 \n",
    "data = enws.text.tolist()\n",
    "data = [re.sub('\\\\S*@\\\\S*\\\\s?','',sent) for sent in data] # 이메일제거\n",
    "data = [re.sub('\\\\s+',' ',sent) for sent in data] # 줄바꿈문자 제거\n",
    "data = [re.sub(\"\\\\'\",\"\",sent) for sent in data] # 작은따옴표 제거 \n",
    "data = [re.sub(\"By\\\\s\\\\w+\\\\s\\\\w+\\\\s\\\\-\\\\s\",'',sent) for sent in data] # writer 이름 제거 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['after', 'decades', 'drowning', 'in', 'deflation', 'japan', 'property', 'market', 'is', 're', 'emerging', 'with', 'average', 'prices', 'for', 'new', 'condos', 'in', 'tokyo', 'hitting', 'levels', 'not', 'seen', 'since', 'according', 'to', 'the', 'real', 'estate', 'economic', 'institute', 'said', 'this', 'week', 'if', 'the', 'trend', 'continues', 'and', 'broadens', 'it', 'could', 'mark', 'turnaround', 'in', 'the', 'long', 'dormant', 'financial', 'fortunes', 'of', 'the', 'worlds', 'third', 'largest', 'economy', 'such', 'turnaround', 'is', 'long', 'overdue', 'japan', 'real', 'estate', 'prices', 'have', 'been', 'falling', 'for', 'nearly', 'years', 'from', 'to', 'falling', 'real', 'estate', 'prices', 'swallowed', 'an', 'estimated', 'trillion', 'of', 'the', 'nation', 'wealth', 'according', 'to', 'the', 'nomura', 'research', 'institute', 'now', 'there', 'evidence', 'from', 'various', 'sectors', 'that', 'the', 'real', 'estate', 'market', 'is', 'rising', 'mt', 'fuji', 'nightfall', 'photo', 'by', 'shutterstock', 'com', 'firstly', 'tokyo', 'new', 'condo', 'sales', 'grew', 'percent', 'between', 'may', 'and', 'december', 'compared', 'to', 'the', 'same', 'period', 'in', 'the', 'average', 'price', 'of', 'new', 'condos', 'in', 'osaka', 'rose', 'by', 'percent', 'in', 'june', 'from', 'year', 'earlier', 'global', 'property', 'guide', 'said', 'late', 'last', 'year', 'secondly', 'resale', 'prices', 'are', 'also', 'rebounding', 'although', 'at', 'slower', 'pace', 'sales', 'of', 'existing', 'condos', 'in', 'and', 'surrounding', 'tokyo', 'grew', 'percent', 'between', 'may', 'and', 'september', 'last', 'year', 'compared', 'with', 'the', 'same', 'period', 'year', 'earlier', 'according', 'to', 'real', 'estate', 'information', 'network', 'for', 'east', 'japan', 'the', 'tokyo', 'stock', 'exchange', 'home', 'price', 'index', 'grew', 'percent', 'in', 'october', 'from', 'year', 'earlier', 'that', 'still', 'percent', 'below', 'the', 'precrisis', 'peak', 'and', 'percent', 'below', 'june', 'prices', 'the', 'earliest', 'data', 'available', 'thirdly', 'though', 'overall', 'land', 'prices', 'are', 'still', 'falling', 'average', 'property', 'prices', 'are', 'still', 'percent', 'below', 'their', 'peak', 'in', 'according', 'to', 'report', 'released', 'last', 'week', 'by', 'the', 'bank', 'of', 'japan', 'land', 'prices', 'near', 'major', 'metropolitan', 'areas', 'are', 'increasing', 'from', 'june', 'to', 'june', 'the', 'average', 'price', 'of', 'land', 'in', 'the', 'tokyo', 'area', 'grew', 'by', 'percent', 'according', 'to', 'the', 'land', 'institute', 'of', 'japan', 'in', 'the', 'osaka', 'area', 'the', 'average', 'land', 'price', 'grew', 'by', 'percent', 'in', 'the', 'same', 'period', 'according', 'to', 'japanese', 'government', 'survey', 'more', 'than', 'two', 'thirds', 'of', 'major', 'urban', 'areas', 'saw', 'their', 'property', 'values', 'rise', 'last', 'summer', 'in', 'july', 'moody', 'upgraded', 'its', 'rating', 'of', 'japan', 'property', 'market', 'from', 'negative', 'to', 'stable', 'fourthly', 'residential', 'construction', 'is', 'increasing', 'the', 'number', 'of', 'new', 'home', 'buildings', 'increased', 'by', 'percent', 'to', 'in', 'the', 'first', 'half', 'of', 'compared', 'to', 'same', 'period', 'last', 'year', 'according', 'to', 'the', 'ministry', 'of', 'land', 'infrastructure', 'transport', 'and', 'tourism', 'fifthly', 'if', 'japans', 'fiscal', 'and', 'monetary', 'efforts', 'including', 'the', 'bank', 'of', 'japans', 'goal', 'of', 'inflation', 'climbing', 'to', 'percent', 'to', 'stimulate', 'the', 'economy', 'succeed', 'interest', 'rates', 'will', 'rise', 'lowering', 'the', 'cost', 'of', 'fixed', 'rate', 'mortgages', 'and', 'thus', 'motivating', 'potential', 'borrowers', 'to', 'take', 'out', 'loans', 'that', 'can', 'be', 'paid', 'back', 'with', 'every', 'cheapening', 'money', 'the', 'road', 'ahead', 'could', 'be', 'bumpy', 'new', 'home', 'sales', 'may', 'be', 'up', 'now', 'because', 'of', 'planned', 'sales', 'tax', 'hike', 'in', 'april', 'but', 'even', 'with', 'tax', 'hike', 'in', 'april', 'the', 'real', 'estate', 'recovery', 'may', 'continue', 'unlike', 'the', 'last', 'sales', 'tax', 'hike', 'in', 'april', 'japan', 'economic', 'policies', 'under', 'prime', 'minister', 'shinzo', 'abe', 'have', 'raised', 'expectations', 'for', 'higher', 'prices', 'ahead', 'and', 'encouraged', 'businesses', 'to', 'invest', 'more', 'to', 'offset', 'any', 'negative', 'impact', 'from', 'the', 'tax', 'hike', 'the', 'abe', 'administration', 'is', 'preparing', 'stimulus', 'package', 'of', 'up', 'to', 'trillion', 'yen', 'about', 'billion']]\n"
     ]
    }
   ],
   "source": [
    "# 단어 토큰화와 텍스트 클린업 \n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence),deacc=True)) # deacc=True: 구두점 제거\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_words[:27460]\n",
    "test = data_words[27460:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192.1622931957245"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = time.time()\n",
    "# bigram과 trigram모델 만들기 \n",
    "bigram_train = gensim.models.Phrases(train,min_count=5,threshold=100) # threshold가 크면 단어구가 적게만들어짐\n",
    "trigram_train = gensim.models.Phrases(bigram_train[train], threshold=100)\n",
    "time.time()-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01:19'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = time.time()\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram_train)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram_train)\n",
    "e = time.time()-s\n",
    "time.strftime('%M:%S',time.gmtime(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용단어 제거하고 bigram만들고 표준형 변환 \n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "def lemmatization(texts, allowed_postags=['NOUN','ADJ','VERB','ADV']):\n",
    "    \"\"\"https://spac.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords 제거 \n",
    "train_nostops = remove_stopwords(train)\n",
    "train_bigrams = make_bigrams(train_nostops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm',disable=['parser','ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lemmatized = lemmatization(train_bigrams, allowed_postags=['NOUN','ADJ','VERB','ADV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 7), (1, 2), (2, 1), (3, 2), (4, 1), (5, 5), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 3), (17, 3), (18, 1), (19, 2), (20, 1), (21, 2), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 3), (28, 1), (29, 1), (30, 2), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 3), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 5), (52, 1), (53, 1), (54, 1), (55, 2), (56, 1), (57, 1), (58, 3), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 2), (69, 1), (70, 6), (71, 1), (72, 1), (73, 1), (74, 2), (75, 1), (76, 2), (77, 1), (78, 3), (79, 4), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 2), (87, 4), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 2), (96, 11), (97, 4), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 13), (104, 3), (105, 1), (106, 3), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 4), (114, 1), (115, 5), (116, 2), (117, 1), (118, 1), (119, 2), (120, 1), (121, 1), (122, 3), (123, 1), (124, 1), (125, 1), (126, 1), (127, 1), (128, 1), (129, 1), (130, 1), (131, 4), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 2), (139, 1), (140, 1), (141, 1), (142, 1), (143, 1), (144, 2), (145, 1), (146, 7), (147, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# LDA 주요 입력값: 사전(id2word), 코퍼스 만들기\n",
    "id2word = corpora.Dictionary(train_lemmatized)\n",
    "texts = train_lemmatized\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "print(corpus[:1])\n",
    "# gensim은 문서안의 각 단어에 대해 유니크한 id를 만든다.\n",
    "# 생성된 코퍼스는 (word_id, word_frequency)의 매핑임 \n",
    "# (0,7) : 단어id 0이 7번 발생함을 의미 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mallet: Coherence 점수로 적정 Topic 갯수 구하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**최적 Mallet Topic Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 lda 토픽수 찾기 \n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "        print(str(num_topics),'done')\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_path = 'd:/pkg/mallet-2.0.8/bin/mallet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 done\n",
      "8 done\n",
      "14 done\n",
      "20 done\n",
      "26 done\n",
      "32 done\n",
      "38 done\n"
     ]
    }
   ],
   "source": [
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=train_lemmatized, start=2, limit=40, step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEICAYAAABF82P+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXxU5fX48c/JRkjCFkLYAiQssgoIYVfAHZW6oriDIghWrVqr1ta23/5qa2ur1pdKREXEWlABrVVEqWwqYBL2fUkIkCAQCGv25fz+mImN6ZBMYCZ3kpz368Urc/fDVebkee5znyOqijHGGFNZkNMBGGOMCUyWIIwxxnhkCcIYY4xHliCMMcZ4ZAnCGGOMR5YgjDHGeOTXBCEiY0Rkh4jsFpGnPGwfLSInRGS9+89vvD3WGGOMf4X468QiEgy8ClwOZAIpIvKJqm6ttOvXqjr2LI/9kZiYGI2Pj/fVX8EYY+q9NWvWHFHVVp62+S1BAIOB3aqaDiAic4HrgCq/5M/l2Pj4eFJTU88paGOMaUhEZO+Ztvmzi6k9sL/CcqZ7XWXDRGSDiHwuIr1reKwxxhg/8WcLQjysqzyvx1qgk6qeFpGrgY+Bbl4e67qIyBRgCkDHjh3PPlpjjDE/4s8WRCbQocJyHHCg4g6qelJVT7s/LwRCRSTGm2MrnGOGqiaqamKrVh670YwxxpwFf7YgUoBuIpIAZAG3ArdX3EFE2gCHVFVFZDCuhHUUOF7dscYYE0iKi4vJzMykoKDA6VA8Cg8PJy4ujtDQUK+P8VuCUNUSEXkQ+AIIBmaq6hYRmerengSMA6aJSAmQD9yqrullPR7rr1iNMeZcZWZm0qRJE+Lj4xHx1EvuHFXl6NGjZGZmkpCQ4PVx/mxBlHcbLay0LqnC51eAV7w91hhjAlVBQUFAJgcAEaFly5ZkZ2fX6Dh7k9oYY3wkEJNDubOJzRKECUhZx/P5aF0mVtDKGOf4tYvJmLOhqjwydx0pGcf4ZtdRnrvpfEKD7XcZY2qb/aszAefzzQdJyTjG8C4tmb82k6nvriG/qNTpsIxpcCxBmIBSUFzKnz7fRvfWTZh972D+cH0fluw4zF1vfceJvGKnwzMmoM2ePZu+ffvSr18/7rrrrnM+n3UxmYDyzsoM9ufk8+6kwYQEB3Hn0E5ER4bxyNz13Pz6SmbfO4Q2zcKdDtOYKv3fv7ew9cBJn56zV7um/PYnvc+4fcuWLTz77LN8++23xMTEkJOTc87XtBaECRhHThfyypLdXNIjlou6/fet+KvPb8usewZx4HgBN01fSVr2aQejNCYwLVmyhHHjxhETEwNAdHT0OZ/TWhAmYLy4eCd5xaU8fXXP/9k2vGsMc6cMZcLMZG5OWsXbEwfRr0NzB6I0pnpV/abvL6rq82G21oIwAWHnoVPMSd7HnUM60jU2yuM+fdo3Y9604USEBXPbG6v5elfNXvoxpj679NJL+eCDDzh69CiAdTGZ+uMPn20jqlEIj1x2XpX7JcREsmDacDpGR3DvrBT+vcHjHI7GNDi9e/fmV7/6FaNGjaJfv3489thj53xO62Iyjlu64zArdmbz62t60iIyrNr9Y5uG8/79w5j8TioPz11HTm4RE4bH+z9QYwLchAkTmDBhgs/OZy0I46ji0jKe/Wwb8S0juHtYvNfHNWscyuxJg7msZ2t++8kWXvhyh711bYyPWYIwjpqbvI/dh0/zy6t7EhZSs/8dw0ODmX7HAG5JjOPlJbt5+qPNlJZZkjDGV6yLyTjmRH4xLyzeydDO0VzRq/VZnSMkOIg/39SXmKhGvLYsjWO5Rbx0a3/CQ4N9HK0x1fPHSCJfOZsWtrUgjGNeWbKL4/nF/PqaXuf0j0pEeGJMD54Z24tFWw4y8e1kThXYW9emdoWHh3P06NGA7OosrwcRHl6zl0ytBWEcsfdoLrNWZjBuQBx92jfzyTknXZhAy8gwHv9wA7fOWM2sewbTqkkjn5zbmOrExcWRmZlZ45oLtaW8olxNWIIwjvjTwu2EBgfxiyu7+/S811/QnuYRoUz7x1rGJa3k3XuH0LFlhE+v0RCpKvPXZvHClzu4YUB7Hr+ie8B2pTglNDS0RtXa6gLrYjK1bnX6URZtOci0UV2Iber7eZVGd4/lvclDOJFfzE1JK30+J05Dk5Z9mtveWM3jH25ARHh1aRq/mLeR4tIyp0MzfmYJwtSqsjLlD59tpW2zcO67qLPfrjOgYwvmTR1GSJAw/vVVrE4/6rdr1VeFJaX8/T+7uOqlr9l64CR/vOF8vn7iYh697DzmrclkyuxU8opKnA7T+JElCFOrFqzLYnPWSZ4c04PGYf4dadQ1tgnzpw0ntmkj7p6ZzBdbDvr1evXJ6vSjXPX3r3nxPzsZ06cN//n5KG4f0pGgIOFnl3Xjjzecz/Kd2dz+xnfk5BY5Ha7xE0sQptbkFZXw/Bfb6dehOdf2a1cr12zXvDHzpg6nV9umTPvHGuYm76uV69ZVx3KL+IX7IX9xaRnv3DuYl2+7gNgmP+4KvH1IR6bfOZCt359kXNJKMo/lORSx8SdLEKbWJC1P59DJQp65pidBQbX3gLNFZBj/nDyEi7q14qkFm3h16e6AHIroJFVlwdpMLn1hOR+ty2La6C58+cgoRp3X6ozHXNm7De/dN4Qjpwq58bWVbPvenvXUN5YgTK34/kQ+M1akcU3ftiTGn/s89TUVERbCmxMSub5/O57/Yge//3QrZfbWNQB7juRyx5vf8dgHG4hvGcGnD1/odRfgoPhoPpw6nCARbrFnPfWOJQhTK55ftIMyhafG9HAshtDgIF64pT/3jkjg7W8zePSD9RSVNNyROIUlpbz81S6ufGkFm7JO8Ifr+zBv6nB6tGlao/N0b9OE+Q8Mp3XTcO6emcyizd/7KWJT2yxBGL/bsP84C9ZlMenCBDpEO/tOQlCQ8MzYnjwxpjv/Wn+A+2anklvY8EbiJO/J4ZqXv+GFxTu5oldrvnpsFHcO7XTWXX/tmzdm3tRh9GnXlGnvreXd1Xt9HLFxgiUI41eqrmGtMVFhPDC6i9PhAK6pOR4Y3ZU/33Q+3+zK5vY3G85InON5RTw5byO3vL6KguJS3r5nEK/cPsAn76M0jwjjvfuGckn3WJ75eLPNsFsPWIIwfvX55oOkZBzjscu70yQ81OlwfmT8INdInG3fn+TmpJVkHc93OiS/UVU+XpfFpX9bzry1mdw/qjOLHx3Fxd1jfXqdxmHBvH7XwAoz7G6ixF6oq7P8miBEZIyI7BCR3SLyVBX7DRKRUhEZV2Hdz0Rks4hsEZFH/Bmn8Y+C4lL+9Pk2erRpwvhBHZwOx6Mre7fh3XsHc/hUIeOmr2TXoVNOh+RzGUdyueutZB55fz0doiP49KEL+eVVPf32Hkr5DLsPXdKVOcn7mfqPtRQUl/rlWsa//JYgRCQYeBW4CugF3CYivc6w35+BLyqs6wNMBgYD/YCxItLNX7Ea/3hnZQb7c/L51TU9Ca7FYa01NaRzS96fMoySMmVc0irW7D3mdEg+UVRSxitLdnHFSyvYsP84/+/6PsyfNpyebWv2EPpsiAg/v6I7v7+uN19tP8Qdb37H8byG0Y1Xn/izBTEY2K2q6apaBMwFrvOw30PAfOBwhXU9gdWqmqeqJcBy4AY/xmp87MjpQl5ZsptLesRyUbczj6UPFL3aNWX+1OG0iAjljjdXs3TH4eoPCmApGTlc/fLX/PXLnVzeszX/+fko7hraqdYT9d3D4nn19gFsyjzBzUmrOFCPu/HqI38miPbA/grLme51PxCR9ri++JMqHbsZGCkiLUUkArgaCMw+CuPRi4t3kldcytNX93Q6FK91bBnBh1OH06VVFJPfSeWjdZlOh1Rjx/OKeGr+Rm5OWkV+USkzJyby6h0DaO2HSRG9dfX5bXnn3sEcPFHATfW0G6++8meC8PSrSuUhDS8BT6rqjzooVXUbrm6nxcAiYAPgcSyiiEwRkVQRSQ3Uedgbmh0HTzEneR93DulI19gop8OpkVZNGjF3ylAGxUfz6PsbePPrdKdD8oqq8q/1WVz2wnI+XJPJlJGdWfzYSC7pcXaV+nxtWJeWvH//f7vxUjNynA7JeMGfCSKTH//WHwccqLRPIjBXRDKAccBrInI9gKq+paoDVHUkkAPs8nQRVZ2hqomqmtiqVeB3ZTQEzy7cRlSjEB657DynQzkrTcJDefueQVzVpw1/+Gwbz32+PaCHa+49msvdM5P52dz1tG8RwScPjuDpq3sSERZY5V56tWvKgmnDaRkZxh1vfsfirYecDslUw58JIgXoJiIJIhIG3Ap8UnEHVU1Q1XhVjQfmAQ+o6scAIhLr/tkRuBGY48dYjY8s3XGYFTuzefjSbrSIDHM6nLMWHhrMK7cP4I4hHUlansaT8zcG3HDNopIyXl26myteXMG6fcf5/XW9WTBtOL3b+aZCnz90iI7gw6nD6NG2Kfe/m2qTJwY4v/2KoaolIvIgrtFJwcBMVd0iIlPd2ys/d6hsvoi0BIqBn6pq/RhaUo8Vl5bx7GfbiG8Zwd3D4p0O55wFBwl/uL4PMVGN+PtXu8jJLeaV2y8gPNS/05R7IzUjh6c/2sTOQ6e5qk8bfvuT3rRp5txzhppoGdWIOZOH8MB7a3lqwSYOnyrkoUu6WoW6ACSB3HSuqcTERE1NTXU6jAbr3VUZPPOvLbx+10Cu7N3G6XB8avaqDH77yRYGdYrmjQmJNGvszEt/J/KKeW7RduYk76N988b837W9uaxXYDxnqKni0jKenL+RBWuzuGtoJ353be+AHg5dX4nIGlVN9LQtsDopTZ11Ir+YFxbvZGjnaK6oo19YVbl7WDzRkWE8+v56xr++infuHVyrI4NUlX9v/J7f/3srObmFTL4ogUcuO4/IRnX3n3BocBB/u7kfrZo04vXl6Rw5XciL4/sHRAvNuNTd/7tMQHllyS6O5xfz62t61duugrF929G8cRhT3k3lpukreXfSEBJiIv1+3X1H8/j1vzazYmc2feOaMeueQfRpH7jPGWpCRPjlVT2JbRLO//t0Kzm5ycy427kWmvkxm4vJnLO9R3OZtTKDcQPi6s0X15lc2C2GuVOGkldUyrjpK9mUecJv1youLeO1Zbu5/MXlrMnI4Xc/6cVHD4yol/d40oUJvHzbBazdd4zxr6/i0MkCp0MyWIIwPvCnhdsJDQ7iF1d2dzqUWtE3rjnzpg4jPDSYW2es4tvdR3x+jTV7jzH25W/4y6IdjO7eiv/8fBQTRyTU6z76a/u14+2Jg9mfk8eNr61k9+HTTofU4FmCMOdkdfpRFm05yLRRXXwyZXRd0blVFAseGE5ciwjueTuFzzb6pkjOifxifvXRJsYlreRkQTEz7hrI63cl0rZZY5+cP9Bd2C2G9+8fRmFJKTcnrWTdPhu86CRLEOaslZW5aj20axbO5JGdnQ6n1rVuGs4H9w+jb1wzHpxzbkVyVJVPNx7gsheWMyd5H/eOSGDxY6O4op6NBvNGn/bNmD9tOE0bh3L7G9+xdHvdnherLrMEYc7agnVZbM46yRNjejTYkSfNIkJ5d9KQH4rkvLh4Z43fut6fk8c9s1J48J/raNM0nE8evJBnxvYiqg6PUDpXnVpGMm/qcLrERnLf7FQ+TN1f/UHG5yxBmLOSV1TC819sp1+H5lzbr53T4TiqvEjOuIFx/P2rXfzmX1soLas+SRSXlpG0PI3LX1xOyp4cfvuTXnz80/r5EPpsuObFGsawzi35xbyNvLZsd0BPeVIfNdxfUcw5SVqezqGThbx2x4CzrmNcn4QEB/H8uL60jArj9eXp5OQW8cL4fjQK8dyyWrvvGE8v2MT2g6e4oldrfndtb9o1bxjPGWoiqlEIMycO4vEPN/CXRTs4fLKQ34ztZf/P1RJLEKbGvj+Rz4wVaVzTty0DO0U7HU7AKB/THxPZiGcXbuN4fhGv35X4o66ikwXFPL9oB//4bi9tmobXy7fOfS0sJIiXxvenVZNGvPXNHrJPF/LCLWdOvsZ3LEGYGnt+0Q7KFJ4a08PpUALS5JGdiY4M44n5G7ltxmrevmcQLSPDWLjpIL/79xaOni5k4vB4fn5F9wb9nKEmgoKEZ8b2onXTRvxx4XaO5Rbx+l0DA67OeX1j/3eaGtmw/zgL1mUxbXQXOkRHOB1OwLppYBwtIkN54L213Jy0iviWESzdkU2f9k15a0IifeOaOx1inTRlZBdiohrxxLyN3OpOvrFNGs7w6tpmD6mN11Rdw1pjosJ4YHQXp8MJeJf0aM179w0hJ7eI7/bk8MzYXnz8wAhLDufoxgFxvDkhkfTsXG6avpI9R3KdDqnesgRhvPb55oOkZBzjscu7W9PeSwM7RbP40ZEs/8XFTLowgZBg+yfnC6O7xzJnylByC11TnmzMPO50SI46VVDsl/PadN/GKwXFpVz+4nIiw0L47OGL6vWUD6buSM8+zd0zk8nJLSLpzoGMPK/+V5UsK1N2Hj5FSsYx1mTkkJJxDBH45slLzup8Nt23OWezVmawPyeff0waYsnBBIzOraJYMG04E95O4d5ZKfz15n5cf0F7p8PyqfyiUtbvP86ava5ksHbfMU4VlAAQE9WIQfEtGNipBWVl6vPhv5YgTLWOnC7k1SW7uaRHLBd2i3E6HGN+JLZpOO/fP5Qps1N55P31ZJ8qrNNTv2SfKvwhGaTuPcaWrBOUuF+87BYbxdi+bUnsFE1ifAs6Rkf4dXp9SxCmWi8u3kl+cSlPX93T6VCM8ahpeCjv3DuYx97fwLMLt3H4VAG/vKpnwL9Qp6qkZZ92JYOMY6zZm0PG0TzA9f5Hv7hmTB7ZmcROrlZC84jarfNuCcJUacfBU8xJ3sfdw+LpGhvldDjGnFGjkGBevu0CYqLCeOPrPWSfKuQv4/oRFhI4AwMKikvZlHXih2SQuvcYx/NcD5hbRISSGB/NbYM7khjfgj7tmzn+MqAlCFOlZxduI6pRCD+7tJvToRhTreAg4XfX9ia2aTjPf7GDo+6H106VZs3JLWLN3mOk7s0hNeMYmzJPUFRaBkDnmEgu79maQfHRDIxvQeeYyICrxmgJwpzR0h2HWbEzm19f05MWkbXbtDXmbIkIP724K62aNOKXCzZx2xurmTlxEDFRjfx6XVUl42geqRmuZJC6N4e0bNc7GqHBQp/2zZg4Ip6B7u4if8fjC5YgjEfFpWU8+9k2EmIiuXtYvNPhGFNjtyR2oGVkGD/951rGTV/J7HuH0LGl797+LyopY8uBEz8kgzV7j3HkdBEATcNDSIyP5sYBcSR2akG/Ds3r5JT4liCMR3OT97H78Glm3DUwoPpwjamJS3u25r37hjLpnRRunL6SWfcMOuvp1E/kF7PW3V2UknGMDfuPU1ji6i7qGB3ByG6tSIx3jS7q2ioq4B+Qe8NelDP/40R+MaOfX0r3Nk2YM3lowPWLGlNTuw+f4u63kjlZUMKMuwYyvGvVw7VVlcxj+T8kgzUZx9h5+BSqruccvds1/WGoaWKnFnW63K69KGdq5JUluzieX8wzY3tZcjD1QtfYJix4YAQTZiYz4e1kXrilPz+pUOiqpLSMbd+fIiUj54eHyodOFgKumhQDOrXgmr5tSYxvQf8OzYkIaxhfndX+LUUkAvg50FFVJ4tIN6C7qn7q9+hMrcs4ksuslRncPDCO3u2sspmpP9o0c9UQnzw7lYfnrmPX4dMArNmbw7p9x8krKgWgffPGDElo6X5DOZrubZo02NkDvEmDbwNrgGHu5UzgQ8ASRD303OfbCQ0O4vErujsdijE+1ywilNmTBvPwnHW8/NUuggR6tGnKzQPjGBgfTWKnFlbZrwJvEkQXVR0vIrcBqGq+eNnvICJjgL8DwcCbqvrcGfYbBKwGxqvqPPe6R4H7AAU2AfeoaoE31zVnZ3X6URZtOcjPLz+vTvepGlOV8NBgpt85kB0HT9EhurHNTFwFb4anFIlIY1xf1IhIF6CwuoNEJBh4FbgK6AXcJiK9zrDfn4EvKqxrDzwMJKpqH1wJ5lYvYjVnqazMVeuhXbPwOj2PjTHeCA4SerVrasmhGt4kiN8Ci4AOIvIe8BXwhBfHDQZ2q2q6qhYBc4HrPOz3EDAfOFxpfQjQWERCgAjggBfXNGdpwbosNmed5IkxPerkeG1jjO9V2cUkIkFAC+BGYCggwM9U9YgX524P7K+wnAkMqXT+9sANwCXAoPL1qpolIn8F9gH5wJeq+qUX1zRnIa+ohOe/2E6/Ds25tsLIDmNMw1ZlC0JVy4AHVfWoqn6mqp96mRzAlUz+55SVll8CnlTV0h8dKNICV2sjAWgHRIrInR4vIjJFRFJFJDU7O9vL0ExFScvTOXSykN+MDfzZL40xtcebh9SLReRx4H3gh+KvqppTzXGZQIcKy3H8bzdRIjDX/cw7BrhaREqAUGCPqmYDiMgCYDjwj8oXUdUZwAxwvSjnxd/HVPD9iXxmrEhjbN+2DOwU7XQ4xpgA4k2CuNf986cV1ilQ3ZPMFKCbiCQAWbgeMt9ecQdVTSj/LCKzgE9V9WMRGQIMdb+DkQ9cCtgr0n7w/KIdlCk8OaaH06EYYwJMtQmi4pd4TahqiYg8iGt0UjAwU1W3iMhU9/akKo79TkTmAWuBEmAd7laC8Z0N+4+zYF0W00Z3oUO07yYxM8bUD9XOxSQiocA0YKR71TLgdVUt9m9oNWdzMXlPVbk5aRUZR3NZ+vhoG+5nTANV1VxM3gxznQ4MBF5z/xnoXmfqsM83HyR17zEeu7y7JQdjjEfePIMYpKr9KiwvEZEN/grI+F9BcSl/+nwbPdo0YfygDtUfYIxpkLxpQZS6354GQEQ6A6VV7G8C3KyVGezPyefX1/RqsJOQGWOq500L4hfAUhFJx/VuQyfgHr9GZfzmyOlCXl2ym0t6xHJht6rnxDfGNGzejGL6qnyKb1wJYruqVjsXkwlMLy7eSX5xKU9f3dPpUIwxAa7aLiYR+SnQWFU3quoGIEJEHvB/aMbXdhw8xZzkfdw5tBNdY6OcDscYE+C8eQYxWVWPly+o6jFgsv9CMv7y7MJtRDUK4WeXdnM6FGNMHeBNggiqWP/BPT13mP9CMv6wdMdhVuzM5uFLu9Ei0v7zGWOq581D6i+AD0QkCdcUG1NxTf9t6oji0jKe/WwbCTGR3D0s3ulwjDF1hDcJ4klgCq63qQX4EnjTn0EZ35qTvI/dh08z466BhIV402g0xhjvRjGVAUlAkohEA3GVp+c2getEfjEvLt7J0M7RXN6rtdPhGGPqEG9GMS0Tkabu5LAeeFtEXvB/aMYXXlmyi+P5xTwzthdelhI3xhjAu4fUzVT1JK6qcm+r6kDgMv+GZXwh40gus1ZmcPPAOHq3a+Z0OMaYOsabBBEiIm2BW4BP/RyP8aHnPt9OaHAQj1/R3elQjDF1kDcJ4ve4RjLtVtUU91xMu/wbljlXq9OPsmjLQaaN6kJs03CnwzHG1EHePKT+EPiwwnI6cJM/gzLnpqxM+cNnW2nXLJzJI6sr/GeMMZ7ZmMd6aMG6LDZnneTJq3oQHhrsdDjGmDrKEkQ9k1dUwvNfbKdfh+b8pG87p8MxxtRhliDqmaTl6Rw6WchvxvYkyGo9GGPOgTfvQbQWkbdE5HP3ci8RmeT/0ExNHTpZwIwVaYzt25aBnaKdDscYU8d504KYhWsUU3l/xU7gEX8FZM7eGyvSKS5Vnriyh9OhGGPqAW8SRIyqfgCUAahqCVZyNOAczyvin8n7uLZfOzq2jHA6HGNMPeBNgsgVkZa4ZnJFRIYCJ/walamxd1buJa+olKmjulS/szHGeMGb2VwfAz4BuojIt0ArYJxfozI1kldUwqyVe7isZyzd2zRxOhxjTD3hzYtya0VkFP+tSb1DVYv9Hpnx2vsp+zmWV8y00dZ6MMb4jrc1qaNUdYuqbgairCZ14CgqKeONFekMjo+2kUvGGJ+ymtR13CcbDnDgRIG1HowxPufXmtQiMkZEdojIbhF5qor9BolIqYiMcy93F5H1Ff6cFBEbWltJWZmStDyNHm2aMLp7K6fDMcbUM36rSe1OJK8ClwOZQIqIfKKqWz3s92f3dQBQ1R1A/wrbs4CPvPkLNSSLtx1i9+HT/P3W/lYMyBjjc97WpL6fmtekHoxrivB0ABGZC1wHbK2030PAfGDQGc5zKZCmqnu9uGaDoaq8tiyNjtERXHN+W6fDMcbUQ97WpJ7u/lMT7YH9FZYzgSEVdxCR9sANwCWcOUHcCsw500VEZAowBaBjx441DLHuWp2ew4b9x/nD9X0ICbYptYwxvufNKKYRIrJYRHaKSLqI7BGRdC/O7anPQystvwQ8qaoe38wWkTDgWirUo/ifE6rOUNVEVU1s1arh9MO/tmw3MVGNGDcwzulQjDH1lDddTG8BjwJrqNkUG5lAhwrLccCBSvskAnPd/ecxwNUiUqKqH7u3XwWsVdVDNbhuvbc56wRf7zrCE2O6W70HY4zfeJMgTqjq52dx7hSgm4gk4HrIfCtwe8UdVDWh/LOIzAI+rZAcAG6jiu6lhmr68jSaNArhzqGdnA7FGFOPeZMglorI88ACoLB8paqureogVS0RkQdxjU4KBmaq6hYRmerenlTV8SISgWsE1P1exNhg7DmSy+ebvuf+UV1oGh7qdDjGmHrMmwRR/mA5scI6xfVguUqquhBYWGmdx8SgqhMrLecBLb2Ir0GZsSKNkOAg7hkR73Qoxph6zptRTBfXRiCmeodOFjB/TRa3DIojtkm40+EYY+o5qyhXh8z8Zg8lZWVMucim1TDG+J9VlKsjTuQV84/Vexnb1woCGWNqh1WUqyPeXZ1BblGpTcpnjKk1VlGuDsgvKuXtbzO4uHsrerZt6nQ4xpgGwirK1QEfpO7naG4R00Z3dToUY0wDUmWCcM+kOsr9xyrKOaC4tIwZK9JJ7NSCwQlWEMgYU3uq7GJyz5F0naqWlFeUs+RQuz7deICs4/n27MEYU+u86WL6VkReAd4HcstXVvcmtTl3ZWXK9GVpdG/dhIu7xzodjjGmgfEmQQx3//x9hXVevUltzs2S7YfZeeg0L43vT15UAPoAABBcSURBVFCQFQQyxtQue5M6QLkKAu0mrkVjxva1gkDGmNpnb1IHqOQ9Oazdd5wpIztbQSBjjCPsTeoANX15Gi0jw7glsUP1OxtjjB/Ym9QBaOuBkyzbkc29FyZYQSBjjGPsTeoANH15GlFWEMgY4zB7kzrA7D2ay2cbDzB5ZGeaNbaCQMYY53gzimmtiNib1LVkxop0QoKCmDQiofqdjTHGj7xpQQAMBuLd+w8QEVR1tt+iaqAOnyrgwzWZ3DQwjtimVhDIGOOsahOEiLwLdAHW89+H0wpYgvCxmd9kUFJaxv0jOzsdijHGeNWCSAR6qar6O5iG7GRBMe+t3svV57clPibS6XCMMcarUUybgTb+DqShe3fVXk4VljB1lE3KZ4wJDGdsQYjIv3F1JTUBtopIMlBYvl1Vr/V/eA1DQXEpb3+7h1HntaJP+2ZOh2OMMUDVXUx/rbUoGrgP12Ry5HSRTeltjAkoZ0wQqrq8/LOItAYGuReTVfWwvwNrKEpKy5ixIo0LOjZniBUEMsYEEG8m67sFSAZuBm4BvhMRe1HORz7b9D37c/KZNqoLIjaltzEmcHgziulXwKDyVoOItAL+A8zzZ2ANgaqrIFC32Cgu69na6XCMMeZHvBnFFFSpS+mol8chImNEZIeI7BaRp6rYb5CIlFZsmYhIcxGZJyLbRWSbiAzz5pp1ybId2Ww/eIqpo7pYQSBjTMDxpgWxSES+AOa4l8cDn1d3kIgEA68ClwOZQIqIfKKqWz3s92dcU4pX9HdgkaqOE5EwIMKLWOuU15btpn3zxlzbv131OxtjTC2rtiWgqr8AXgf6Av2AGar6hBfnHgzsVtV0VS0C5gLXedjvIWA+8EMrRUSaAiOBt9wxFKnqcS+uWWekZOSQknGMyRclEGoFgYwxAeiM30wi0lVERgCo6gJVfUxVHwWOiog34zHbA/srLGe611W8RnvgBiCp0rGdgWzgbRFZJyJviki9er04aVka0ZFhjB/U0elQjDHGo6p+dX0JOOVhfZ57W3U8dapXnq7jJeBJVa1cgCgEGABMV9ULgFzA4zMMEZkiIqkikpqdne1FWM7bfvAkX20/zMTh8TQOs4JAxpjAVNUziHhV3Vh5paqmiki8F+fOBCrWy4wDDlTaJxGY6x7eGQNcLSIlwGogU1W/c+83jzMkCFWdAcwASExMrBPzRSUtSyMyLJgJw+KdDsUYY86oqgRR1XzTjb04dwrQTUQSgCzgVuD2ijuo6g9FD0RkFvCpqn7sXt4vIt1VdQdwKfCjh9t11f6cPP698XvuHRFPswgrCGSMCVxVdTGliMjkyitFZBKwproTu2tXP4hrdNI24ANV3SIiU0VkqhexPQS8JyIbgf7AH704JuDNWJFOkMCkC21Kb2NMYKuqBfEI8JGI3MF/E0IiEIbrwXK1VHUhsLDSusoPpMvXT6y0vN59vXoj+1QhH6Tu56YBcbRpZgWBjDGBraq5mA4Bw0XkYqCPe/VnqrqkViKrh2at3ENRaRlTrCCQMaYO8KYm9VJgaS3EUq+dKihm9qq9XNWnDZ1bRTkdjjHGVMve0Kol7323j1MFJUwb1dXpUIwxxiuWIGpBQXEpb32zh4u6xXB+nBUEMsbUDZYgasH8tZlknypkmpUTNcbUIZYg/KyktIzXl6fTr0NzhnVp6XQ4xhjjNUsQfvb55oPsy8mzgkDGmDrHEoQfqSqvLUujS6tIruhlBYGMMXWLJQg/Wr4zm23fn7SCQMaYOskShB9NX5ZG22bhXNe/ffU7G2NMgLEE4Sdr9h7juz053HdRZ8JC7DYbY+oe++byk+nL0mgeEcptgztUv7MxxgQgSxB+sPPQKf6z7RATh8cTEeZN2W9jjAk8liD8IGl5GhFWEMgYU8dZgvCxzGN5fLL+ALcN7kiLyDCnwzHGmLNmCcLH3vx6DyJw30UJ1e9sjDEBzBKEDx09XcjclH1c3789bZt5U5XVGGMClyUIH5q1MoPCkjLut0n5jDH1gCUIHzldWMI7KzO4slcbusZaQSBjTN1nCcJH5ny3j5MFJUwbba0HY0z9YAnCBwpLSnnzm3RGdG1Jvw7NnQ7HGGN8whKED3y0NotDJwutnKgxpl6xBHGOSsuU11ekc377ZozoagWBjDH1hyWIc7Ro80H2HMnlgdFWEMgYU79YgjgHqsr05bvpHBPJFb3bOB2OMcb4lCWIc/DN7iNszjrJ/aM6E2wFgYwx9YwliHPw2tI0WjdtxPUXWEEgY0z949cEISJjRGSHiOwWkaeq2G+QiJSKyLgK6zJEZJOIrBeRVH/GeTbW7TvGqvSjTL6oM41Cgp0OxxhjfM5vxQpEJBh4FbgcyARSROQTVd3qYb8/A194OM3FqnrEXzGei6TlaTRrHMqtgzs6HYoxxviFP1sQg4HdqpquqkXAXOA6D/s9BMwHDvsxFp/affgUX2w5xIRhnYhqZAWBjDH1kz8TRHtgf4XlTPe6H4hIe+AGIMnD8Qp8KSJrRGSK36I8C0nL0wkPDWLiCJvS2xhTf/nz119Pw3q00vJLwJOqWurhHYIRqnpARGKBxSKyXVVX/M9FXMljCkDHjv7v7jlwPJ+P12Vx59BORFtBIGNMPebPFkQm0KHCchxwoNI+icBcEckAxgGvicj1AKp6wP3zMPARri6r/6GqM1Q1UVUTW7Vq5du/gQdvfr0HgMkjO/v9WsYY4yR/JogUoJuIJIhIGHAr8EnFHVQ1QVXjVTUemAc8oKofi0ikiDQBEJFI4Apgsx9j9UpObhFzkvdxXf/2tG9uBYGMMfWb37qYVLVERB7ENTopGJipqltEZKp7u6fnDuVaAx+5u51CgH+q6iJ/xeqtd1ZmkF9cytRR1nowxtR/fh2Co6oLgYWV1nlMDKo6scLndKCfP2OrqdzCEt5ZlcHlvVrTrXUTp8Mxxhi/szepvTQneR/H84qtIJAxpsGwBOGFopIy3vx6D0M7RzOgYwunwzHGmFphCcILH6/P4uDJAqaNtoJAxpiGwxJENUrLlKTlafRu15SR3WKcDscYY2qNJYhqLN56kPTsXKZZQSBjTANjCaIKqsr0ZWnEt4zgqj5tnQ7HGGNqlSWIKqxMO8qGzBPcP6qLFQQyxjQ4liCqMH1ZGrFNGnHjACsIZIxpeCxBnMHGzON8s/sIky5MsIJAxpgGyRLEGUxflkbT8BBuH2IFgYwxDZMlCA/Ssk+zaMtB7h4WT5PwUKfDMcYYR1iC8GDG8nTCgoOYOCLe6VCMMcYxliAq+f5EPgvWZXLroA7ERDVyOhxjjHGMJYhK3vp6D2UK911kU3obYxo2SxAVHM8r4p/J+7i2Xzs6REc4HY4xxjjKEkQF76zcS15RKVNH2ZTexhhjCcItr6iEWSv3cFnPWLq3sYJAxhhjCcLt/ZT9HLOCQMYY8wNLEEBxaRlvrEhncEI0AztFOx2OMcYEBEsQwL/WH+DAiQJrPRhjTAUNPkGUuQsC9WzblNHntXI6HGOMCRghTgfgtLziUhI7teCibq2sIJAxxlTQ4BNEVKMQnrupr9NhGGNMwGnwXUzGGGM8swRhjDHGI0sQxhhjPLIEYYwxxiNLEMYYYzyyBGGMMcYjSxDGGGM8sgRhjDHGI1FVp2PwGRHJBvY6HUcVYoAjTgfhhboSJ9SdWC1O36srsQZ6nJ1U1eM8Q/UqQQQ6EUlV1USn46hOXYkT6k6sFqfv1ZVY60qcnlgXkzHGGI8sQRhjjPHIEkTtmuF0AF6qK3FC3YnV4vS9uhJrXYnzf9gzCGOMMR5ZC8IYY4xHliBqiYhkiMgmEVkvIqlOx1NORGaKyGER2VxhXbSILBaRXe6fLZyM0R2Tpzh/JyJZ7nu6XkSudjJGd0wdRGSpiGwTkS0i8jP3+kC8p2eKNaDuq4iEi0iyiGxwx/l/7vUBdU+riDOg7mdNWBdTLRGRDCBRVQNqPLSIjAROA7NVtY973V+AHFV9TkSeAlqo6pMBGOfvgNOq+lcnY6tIRNoCbVV1rYg0AdYA1wMTCbx7eqZYbyGA7qu4Sj1GquppEQkFvgF+BtxIAN3TKuIcQwDdz5qwFkQDp6orgJxKq68D3nF/fgfXl4ajzhBnwFHV71V1rfvzKWAb0J7AvKdnijWgqMtp92Ko+48SYPe0ijjrLEsQtUeBL0VkjYhMcTqYarRW1e/B9SUCxDocT1UeFJGN7i4ox7ttKhKReOAC4DsC/J5WihUC7L6KSLCIrAcOA4tVNSDv6RnihAC7n96yBFF7RqjqAOAq4KfuLhNzbqYDXYD+wPfA35wN579EJAqYDzyiqiedjqcqHmINuPuqqqWq2h+IAwaLSB+nY/LkDHEG3P30liWIWqKqB9w/DwMfAYOdjahKh9z90+X91IcdjscjVT3k/gdZBrxBgNxTd//zfOA9VV3gXh2Q99RTrIF6XwFU9TiwDFe/fkDeU/hxnIF8P6tjCaIWiEik+yEgIhIJXAFsrvooR30CTHB/ngD8y8FYzqj8y8HtBgLgnrofVL4FbFPVFypsCrh7eqZYA+2+ikgrEWnu/twYuAzYToDd0zPFGWj3syZsFFMtEJHOuFoNACHAP1X1WQdD+oGIzAFG45px8hDwW+Bj4AOgI7APuFlVHX1AfIY4R+NqtiuQAdxf3iftFBG5EPga2ASUuVc/jatvP9Du6ZlivY0Auq8i0hfXQ+hgXL/UfqCqvxeRlgTQPa0izncJoPtZE5YgjDHGeGRdTMYYYzyyBGGMMcYjSxDGGGM8sgRhjDHGI0sQxhhjPLIEYRosEVER+VuF5cfdEwD68hr3VJjFs0j+O6PvczU8z8LyMfbG1BYb5moaLBEpwDX1wSBVPSIijwNRqvo7P10vgwCc0deYM7EWhGnISnCVg3y08gYRmSUi4yosn3b/HC0iy0XkAxHZKSLPicgd7joAm0SkS3UXFZfnRWSz+5jxFc69QkQ+EpGtIpIkIkHubRkiEuP+fLd74rcN7pewEJGb3efbICIrfHFzjAlxOgBjHPYqsNFdA8Nb/YCeuKYfTwfeVNXB4iq48xDwSDXH34jrzdp+uN4MT6nwpT4Y6AXsBRa5951XfqCI9AZ+hWvyxyMiEu3e9BvgSlXNsq4o4yvWgjANmnv20tnAwzU4LMVdS6EQSAO+dK/fBMR7cfyFwBz3BG6HgOXAIPe2ZFVNV9VSYI5734ouAeaVd1NVmFriW2CWiEzGNdWDMefMEoQx8BIwCYissK4E978P96R2YRW2FVb4XFZhuQzvWuVSxbbKDwUrL4uHdajqVODXQAdgvXueImPOiSUI0+C5fwv/AFeSKJcBDHR/vg5XdTBfWQGMdxeXaQWMBJLd2waLSIL72cN4XGUrK/oKuKU8AZR3MYlIF1X9TlV/AxzBlSiMOSeWIIxx+Ruu5wHl3gBGiUgyMATI9eG1PgI2AhuAJcATqnrQvW0V8ByuKaH38N9ZgAFQ1S3As8ByEdkAlE/T/bz7gfdmXAlogw/jNQ2UDXM1JkCIyGjgcVUd63QsxoC1IIwxxpyBtSCMMcZ4ZC0IY4wxHlmCMMYY45ElCGOMMR5ZgjDGGOORJQhjjDEeWYIwxhjj0f8Hv3ADdVBNCDgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show graph\n",
    "limit = 40; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel('Num Topics')\n",
    "plt.ylabel('Coherence score')\n",
    "plt.legend(('coherence_values'), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics =  2  has Coherence Value of 0.4428\n",
      "Num Topics =  8  has Coherence Value of 0.4729\n",
      "Num Topics =  14  has Coherence Value of 0.498\n",
      "Num Topics =  20  has Coherence Value of 0.4851\n",
      "Num Topics =  26  has Coherence Value of 0.4939\n",
      "Num Topics =  32  has Coherence Value of 0.4811\n",
      "Num Topics =  38  has Coherence Value of 0.4844\n"
     ]
    }
   ],
   "source": [
    "for m, cv in zip(x, coherence_values):\n",
    "    print('Num Topics = ',m,' has Coherence Value of', round(cv,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.094*\"bank\" + 0.058*\"financial\" + 0.024*\"risk\" + 0.019*\"loan\" + '\n",
      "  '0.019*\"capital\" + 0.016*\"crisis\" + 0.012*\"credit\" + 0.012*\"banking\" + '\n",
      "  '0.011*\"firm\" + 0.011*\"sector\"'),\n",
      " (1,\n",
      "  '0.035*\"rule\" + 0.028*\"country\" + 0.020*\"finance\" + 0.015*\"reform\" + '\n",
      "  '0.015*\"german\" + 0.015*\"european\" + 0.014*\"minister\" + 0.013*\"make\" + '\n",
      "  '0.012*\"euro\" + 0.010*\"member\"'),\n",
      " (2,\n",
      "  '0.017*\"year\" + 0.015*\"company\" + 0.011*\"industry\" + 0.010*\"home\" + '\n",
      "  '0.009*\"business\" + 0.009*\"accord\" + 0.009*\"sale\" + 0.008*\"price\" + '\n",
      "  '0.008*\"project\" + 0.008*\"country\"'),\n",
      " (3,\n",
      "  '0.043*\"market\" + 0.031*\"week\" + 0.030*\"report\" + 0.020*\"month\" + '\n",
      "  '0.020*\"datum\" + 0.019*\"high\" + 0.019*\"oil\" + 0.019*\"price\" + 0.015*\"rise\" + '\n",
      "  '0.015*\"stock\"'),\n",
      " (4,\n",
      "  '0.086*\"percent\" + 0.066*\"growth\" + 0.057*\"year\" + 0.041*\"economy\" + '\n",
      "  '0.025*\"expect\" + 0.022*\"month\" + 0.022*\"quarter\" + 0.020*\"economic\" + '\n",
      "  '0.019*\"rise\" + 0.018*\"forecast\"'),\n",
      " (5,\n",
      "  '0.059*\"market\" + 0.039*\"bond\" + 0.037*\"year\" + 0.031*\"investor\" + '\n",
      "  '0.024*\"fund\" + 0.023*\"currency\" + 0.021*\"dollar\" + 0.019*\"yield\" + '\n",
      "  '0.014*\"high\" + 0.013*\"percent\"'),\n",
      " (6,\n",
      "  '0.128*\"rate\" + 0.039*\"inflation\" + 0.038*\"interest\" + 0.024*\"policy\" + '\n",
      "  '0.021*\"cut\" + 0.020*\"raise\" + 0.019*\"feed\" + 0.018*\"hike\" + 0.014*\"year\" + '\n",
      "  '0.013*\"central\"'),\n",
      " (7,\n",
      "  '0.079*\"trade\" + 0.035*\"trump\" + 0.034*\"chinese\" + 0.031*\"tariff\" + '\n",
      "  '0.024*\"good\" + 0.019*\"import\" + 0.016*\"export\" + 0.016*\"world\" + '\n",
      "  '0.015*\"country\" + 0.014*\"global\"'),\n",
      " (8,\n",
      "  '0.025*\"tax\" + 0.021*\"job\" + 0.018*\"pay\" + 0.015*\"work\" + 0.014*\"worker\" + '\n",
      "  '0.014*\"year\" + 0.013*\"percent\" + 0.013*\"people\" + 0.012*\"make\" + '\n",
      "  '0.011*\"income\"'),\n",
      " (9,\n",
      "  '0.065*\"policy\" + 0.032*\"economy\" + 0.026*\"monetary\" + 0.021*\"target\" + '\n",
      "  '0.020*\"ecb\" + 0.019*\"inflation\" + 0.016*\"economic\" + 0.015*\"stimulus\" + '\n",
      "  '0.014*\"risk\" + 0.014*\"central\"'),\n",
      " (10,\n",
      "  '0.041*\"deal\" + 0.035*\"talk\" + 0.026*\"official\" + 0.023*\"agreement\" + '\n",
      "  '0.017*\"trade\" + 0.015*\"meet\" + 0.015*\"week\" + 0.014*\"negotiation\" + '\n",
      "  '0.014*\"issue\" + 0.014*\"meeting\"'),\n",
      " (11,\n",
      "  '0.015*\"company\" + 0.011*\"report\" + 0.010*\"sanction\" + 0.010*\"case\" + '\n",
      "  '0.009*\"official\" + 0.009*\"comment\" + 0.008*\"include\" + 0.007*\"foreign\" + '\n",
      "  '0.007*\"firm\" + 0.007*\"statement\"'),\n",
      " (12,\n",
      "  '0.081*\"government\" + 0.044*\"year\" + 0.039*\"debt\" + 0.026*\"budget\" + '\n",
      "  '0.022*\"fiscal\" + 0.022*\"plan\" + 0.020*\"cut\" + 0.020*\"tax\" + 0.017*\"deficit\" '\n",
      "  '+ 0.016*\"percent\"'),\n",
      " (13,\n",
      "  '0.027*\"leave\" + 0.022*\"vote\" + 0.017*\"election\" + 0.016*\"government\" + '\n",
      "  '0.015*\"political\" + 0.010*\"party\" + 0.010*\"parliament\" + 0.010*\"brexit\" + '\n",
      "  '0.009*\"british\" + 0.009*\"britain\"')]\n"
     ]
    }
   ],
   "source": [
    "optimal_model = model_list[2]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mallet model 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(optimal_model, open('model/ldamallet.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mallet model 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = pickle.load(open('model/ldamallet.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topic 확률 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords 제거 \n",
    "test_nostops = remove_stopwords(test)\n",
    "test_bigrams = make_bigrams(test_nostops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm',disable=['parser','ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lemmatized = lemmatization(test_bigrams, allowed_postags=['NOUN','ADJ','VERB','ADV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA 주요 입력값: 사전(id2word), 코퍼스 만들기\n",
    "# test_id2word = corpora.Dictionary(test_lemmatized)\n",
    "test_texts = test_lemmatized\n",
    "test_corpus = [id2word.doc2bow(text) for text in test_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_topic_prob = model1[corpus]\n",
    "test_topic_prob = model1[test_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_topic_prob = pd.DataFrame([{k:v for k,v in t} for t in train_topic_prob])\n",
    "te_topic_prob = pd.DataFrame([{k:v for k,v in t} for t in test_topic_prob])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27460, 14)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_topic_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8083, 14)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_topic_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.046889</td>\n",
       "      <td>0.017515</td>\n",
       "      <td>0.190355</td>\n",
       "      <td>0.109895</td>\n",
       "      <td>0.223134</td>\n",
       "      <td>0.056681</td>\n",
       "      <td>0.049869</td>\n",
       "      <td>0.019644</td>\n",
       "      <td>0.058809</td>\n",
       "      <td>0.103083</td>\n",
       "      <td>0.017941</td>\n",
       "      <td>0.028158</td>\n",
       "      <td>0.052849</td>\n",
       "      <td>0.025178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.326864</td>\n",
       "      <td>0.043484</td>\n",
       "      <td>0.091103</td>\n",
       "      <td>0.027611</td>\n",
       "      <td>0.062158</td>\n",
       "      <td>0.029478</td>\n",
       "      <td>0.055622</td>\n",
       "      <td>0.037415</td>\n",
       "      <td>0.063559</td>\n",
       "      <td>0.019675</td>\n",
       "      <td>0.028545</td>\n",
       "      <td>0.102774</td>\n",
       "      <td>0.065893</td>\n",
       "      <td>0.045818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.058407</td>\n",
       "      <td>0.071352</td>\n",
       "      <td>0.042225</td>\n",
       "      <td>0.113423</td>\n",
       "      <td>0.070273</td>\n",
       "      <td>0.046540</td>\n",
       "      <td>0.085375</td>\n",
       "      <td>0.040068</td>\n",
       "      <td>0.048698</td>\n",
       "      <td>0.241794</td>\n",
       "      <td>0.045462</td>\n",
       "      <td>0.043304</td>\n",
       "      <td>0.049777</td>\n",
       "      <td>0.043304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.056878</td>\n",
       "      <td>0.022310</td>\n",
       "      <td>0.134656</td>\n",
       "      <td>0.076014</td>\n",
       "      <td>0.028483</td>\n",
       "      <td>0.043915</td>\n",
       "      <td>0.026014</td>\n",
       "      <td>0.035891</td>\n",
       "      <td>0.093298</td>\n",
       "      <td>0.031570</td>\n",
       "      <td>0.041446</td>\n",
       "      <td>0.352557</td>\n",
       "      <td>0.030335</td>\n",
       "      <td>0.026631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041333</td>\n",
       "      <td>0.061135</td>\n",
       "      <td>0.160695</td>\n",
       "      <td>0.090288</td>\n",
       "      <td>0.080387</td>\n",
       "      <td>0.089738</td>\n",
       "      <td>0.042433</td>\n",
       "      <td>0.075986</td>\n",
       "      <td>0.131542</td>\n",
       "      <td>0.057284</td>\n",
       "      <td>0.033082</td>\n",
       "      <td>0.038032</td>\n",
       "      <td>0.075436</td>\n",
       "      <td>0.022631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.046889  0.017515  0.190355  0.109895  0.223134  0.056681  0.049869   \n",
       "1  0.326864  0.043484  0.091103  0.027611  0.062158  0.029478  0.055622   \n",
       "2  0.058407  0.071352  0.042225  0.113423  0.070273  0.046540  0.085375   \n",
       "3  0.056878  0.022310  0.134656  0.076014  0.028483  0.043915  0.026014   \n",
       "4  0.041333  0.061135  0.160695  0.090288  0.080387  0.089738  0.042433   \n",
       "\n",
       "         7         8         9         10        11        12        13  \n",
       "0  0.019644  0.058809  0.103083  0.017941  0.028158  0.052849  0.025178  \n",
       "1  0.037415  0.063559  0.019675  0.028545  0.102774  0.065893  0.045818  \n",
       "2  0.040068  0.048698  0.241794  0.045462  0.043304  0.049777  0.043304  \n",
       "3  0.035891  0.093298  0.031570  0.041446  0.352557  0.030335  0.026631  \n",
       "4  0.075986  0.131542  0.057284  0.033082  0.038032  0.075436  0.022631  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_topic_prob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27460"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tridx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mallet 이용\n",
    "# 기사별 토픽확률 생성 \n",
    "# 2020.2월까지 train\n",
    "# 2020.3월부터 test\n",
    "topic_prob = pd.concat([tr_topic_prob,te_topic_prob],axis=0).reset_index(drop=True)\n",
    "topic_prob = pd.concat([enws[['id','dat']].reset_index(drop=True),topic_prob],axis=1)\n",
    "topic_prob.loc[:27460,'tr_te'] = 1\n",
    "topic_prob.loc[27460:,'tr_te'] = 2\n",
    "topic_prob.tr_te = topic_prob.tr_te.astype(int)\n",
    "topic_prob.columns = ['id','dat']+['topic'+str(i+1) for i in range(14)]+['tr_te']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_prob.to_csv('data/topic_prob.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dat</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>topic10</th>\n",
       "      <th>topic11</th>\n",
       "      <th>topic12</th>\n",
       "      <th>topic13</th>\n",
       "      <th>topic14</th>\n",
       "      <th>tr_te</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-22</td>\n",
       "      <td>0.046889</td>\n",
       "      <td>0.017515</td>\n",
       "      <td>0.190355</td>\n",
       "      <td>0.109895</td>\n",
       "      <td>0.223134</td>\n",
       "      <td>0.056681</td>\n",
       "      <td>0.049869</td>\n",
       "      <td>0.019644</td>\n",
       "      <td>0.058809</td>\n",
       "      <td>0.103083</td>\n",
       "      <td>0.017941</td>\n",
       "      <td>0.028158</td>\n",
       "      <td>0.052849</td>\n",
       "      <td>0.025178</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-01-22</td>\n",
       "      <td>0.326864</td>\n",
       "      <td>0.043484</td>\n",
       "      <td>0.091103</td>\n",
       "      <td>0.027611</td>\n",
       "      <td>0.062158</td>\n",
       "      <td>0.029478</td>\n",
       "      <td>0.055622</td>\n",
       "      <td>0.037415</td>\n",
       "      <td>0.063559</td>\n",
       "      <td>0.019675</td>\n",
       "      <td>0.028545</td>\n",
       "      <td>0.102774</td>\n",
       "      <td>0.065893</td>\n",
       "      <td>0.045818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2014-01-23</td>\n",
       "      <td>0.058407</td>\n",
       "      <td>0.071352</td>\n",
       "      <td>0.042225</td>\n",
       "      <td>0.113423</td>\n",
       "      <td>0.070273</td>\n",
       "      <td>0.046540</td>\n",
       "      <td>0.085375</td>\n",
       "      <td>0.040068</td>\n",
       "      <td>0.048698</td>\n",
       "      <td>0.241794</td>\n",
       "      <td>0.045462</td>\n",
       "      <td>0.043304</td>\n",
       "      <td>0.049777</td>\n",
       "      <td>0.043304</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2014-01-23</td>\n",
       "      <td>0.056878</td>\n",
       "      <td>0.022310</td>\n",
       "      <td>0.134656</td>\n",
       "      <td>0.076014</td>\n",
       "      <td>0.028483</td>\n",
       "      <td>0.043915</td>\n",
       "      <td>0.026014</td>\n",
       "      <td>0.035891</td>\n",
       "      <td>0.093298</td>\n",
       "      <td>0.031570</td>\n",
       "      <td>0.041446</td>\n",
       "      <td>0.352557</td>\n",
       "      <td>0.030335</td>\n",
       "      <td>0.026631</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2014-01-23</td>\n",
       "      <td>0.041333</td>\n",
       "      <td>0.061135</td>\n",
       "      <td>0.160695</td>\n",
       "      <td>0.090288</td>\n",
       "      <td>0.080387</td>\n",
       "      <td>0.089738</td>\n",
       "      <td>0.042433</td>\n",
       "      <td>0.075986</td>\n",
       "      <td>0.131542</td>\n",
       "      <td>0.057284</td>\n",
       "      <td>0.033082</td>\n",
       "      <td>0.038032</td>\n",
       "      <td>0.075436</td>\n",
       "      <td>0.022631</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        dat    topic1    topic2    topic3    topic4    topic5    topic6  \\\n",
       "0   1 2014-01-22  0.046889  0.017515  0.190355  0.109895  0.223134  0.056681   \n",
       "1   2 2014-01-22  0.326864  0.043484  0.091103  0.027611  0.062158  0.029478   \n",
       "2   3 2014-01-23  0.058407  0.071352  0.042225  0.113423  0.070273  0.046540   \n",
       "3   4 2014-01-23  0.056878  0.022310  0.134656  0.076014  0.028483  0.043915   \n",
       "4   5 2014-01-23  0.041333  0.061135  0.160695  0.090288  0.080387  0.089738   \n",
       "\n",
       "     topic7    topic8    topic9   topic10   topic11   topic12   topic13  \\\n",
       "0  0.049869  0.019644  0.058809  0.103083  0.017941  0.028158  0.052849   \n",
       "1  0.055622  0.037415  0.063559  0.019675  0.028545  0.102774  0.065893   \n",
       "2  0.085375  0.040068  0.048698  0.241794  0.045462  0.043304  0.049777   \n",
       "3  0.026014  0.035891  0.093298  0.031570  0.041446  0.352557  0.030335   \n",
       "4  0.042433  0.075986  0.131542  0.057284  0.033082  0.038032  0.075436   \n",
       "\n",
       "    topic14  tr_te  \n",
       "0  0.025178      1  \n",
       "1  0.045818      1  \n",
       "2  0.043304      1  \n",
       "3  0.026631      1  \n",
       "4  0.022631      1  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_prob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (이하) 기타 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1개 Mallet Topic Model 만들기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA Mallet 모델 만들기 \n",
    "mallet_path = 'd:/pkg/mallet-2.0.8/bin/mallet'\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus = corpus, num_topics = 20, id2word = id2word)\n",
    "# Show Topics\n",
    "pprint(ldamallet.show_topics(formatted=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.49830146488360905\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=train_lemmatized, dictionary = id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ',coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **기타 코드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('accord', 7),\n",
       "  ('ahead', 2),\n",
       "  ('also', 1),\n",
       "  ('area', 2),\n",
       "  ('available', 1),\n",
       "  ('average', 5),\n",
       "  ('back', 1),\n",
       "  ('bank', 1),\n",
       "  ('borrower', 1),\n",
       "  ('broaden', 1),\n",
       "  ('building', 1),\n",
       "  ('bumpy', 1),\n",
       "  ('business', 1),\n",
       "  ('cheapen', 1),\n",
       "  ('climb', 1),\n",
       "  ('com', 1),\n",
       "  ('compare', 3),\n",
       "  ('condo', 3),\n",
       "  ('construction', 1),\n",
       "  ('continue', 2),\n",
       "  ('cost', 1),\n",
       "  ('could', 2),\n",
       "  ('datum', 1),\n",
       "  ('decade', 1),\n",
       "  ('deflation', 1),\n",
       "  ('dormant', 1),\n",
       "  ('drown', 1),\n",
       "  ('earlier', 3),\n",
       "  ('early', 1),\n",
       "  ('economic', 1),\n",
       "  ('economy', 2),\n",
       "  ('effort', 1),\n",
       "  ('emerge', 1),\n",
       "  ('encourage', 1),\n",
       "  ('estimate', 1),\n",
       "  ('even', 1),\n",
       "  ('evidence', 1),\n",
       "  ('exist', 1),\n",
       "  ('expectation', 1),\n",
       "  ('fall', 3),\n",
       "  ('fifthly', 1),\n",
       "  ('financial', 1),\n",
       "  ('first', 1),\n",
       "  ('firstly', 1),\n",
       "  ('fiscal', 1),\n",
       "  ('fix', 1),\n",
       "  ('fortune', 1),\n",
       "  ('fourthly', 1),\n",
       "  ('global', 1),\n",
       "  ('goal', 1),\n",
       "  ('government', 1),\n",
       "  ('grow', 5),\n",
       "  ('guide', 1),\n",
       "  ('high', 1),\n",
       "  ('hit', 1),\n",
       "  ('home', 2),\n",
       "  ('impact', 1),\n",
       "  ('include', 1),\n",
       "  ('increase', 3),\n",
       "  ('index', 1),\n",
       "  ('inflation', 1),\n",
       "  ('information', 1),\n",
       "  ('infrastructure', 1),\n",
       "  ('institute', 1),\n",
       "  ('interest', 1),\n",
       "  ('invest', 1),\n",
       "  ('japan', 1),\n",
       "  ('japanese', 1),\n",
       "  ('land', 2),\n",
       "  ('large', 1),\n",
       "  ('last', 6),\n",
       "  ('late', 1),\n",
       "  ('level', 1),\n",
       "  ('loan', 1),\n",
       "  ('long', 2),\n",
       "  ('lower', 1),\n",
       "  ('major', 2),\n",
       "  ('mark', 1),\n",
       "  ('market', 3),\n",
       "  ('may', 4),\n",
       "  ('monetary', 1),\n",
       "  ('money', 1),\n",
       "  ('mortgage', 1),\n",
       "  ('motivate', 1),\n",
       "  ('nation', 1),\n",
       "  ('nearly', 1),\n",
       "  ('negative', 2),\n",
       "  ('new', 4),\n",
       "  ('number', 1),\n",
       "  ('offset', 1),\n",
       "  ('overall', 1),\n",
       "  ('overdue', 1),\n",
       "  ('pace', 1),\n",
       "  ('package', 1),\n",
       "  ('pay', 1),\n",
       "  ('peak', 2),\n",
       "  ('percent', 11),\n",
       "  ('period', 4),\n",
       "  ('plan', 1),\n",
       "  ('policy', 1),\n",
       "  ('potential', 1),\n",
       "  ('precrisis', 1),\n",
       "  ('prepare', 1),\n",
       "  ('price', 13),\n",
       "  ('property', 3),\n",
       "  ('raise', 1),\n",
       "  ('rate', 3),\n",
       "  ('rebound', 1),\n",
       "  ('recovery', 1),\n",
       "  ('release', 1),\n",
       "  ('report', 1),\n",
       "  ('resale', 1),\n",
       "  ('residential', 1),\n",
       "  ('rise', 4),\n",
       "  ('road', 1),\n",
       "  ('sale', 5),\n",
       "  ('say', 2),\n",
       "  ('secondly', 1),\n",
       "  ('sector', 1),\n",
       "  ('see', 2),\n",
       "  ('slow', 1),\n",
       "  ('stable', 1),\n",
       "  ('still', 3),\n",
       "  ('stimulate', 1),\n",
       "  ('stimulus', 1),\n",
       "  ('succeed', 1),\n",
       "  ('summer', 1),\n",
       "  ('surround', 1),\n",
       "  ('survey', 1),\n",
       "  ('swallow', 1),\n",
       "  ('take', 1),\n",
       "  ('tax', 4),\n",
       "  ('third', 1),\n",
       "  ('thirdly', 1),\n",
       "  ('thus', 1),\n",
       "  ('tourism', 1),\n",
       "  ('transport', 1),\n",
       "  ('trend', 1),\n",
       "  ('turnaround', 2),\n",
       "  ('upgrade', 1),\n",
       "  ('urban', 1),\n",
       "  ('value', 1),\n",
       "  ('various', 1),\n",
       "  ('wealth', 1),\n",
       "  ('week', 2),\n",
       "  ('world', 1),\n",
       "  ('year', 7),\n",
       "  ('yen', 1)]]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토픽 모델 만들기 \n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus = corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20,\n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.044*\"say\" + 0.014*\"year\" + 0.014*\"go\" + 0.013*\"make\" + 0.012*\"people\" + '\n",
      "  '0.012*\"would\" + 0.011*\"time\" + 0.011*\"take\" + 0.010*\"could\" + 0.010*\"get\"'),\n",
      " (1,\n",
      "  '0.076*\"home\" + 0.057*\"price\" + 0.055*\"housing\" + 0.043*\"property\" + '\n",
      "  '0.039*\"sale\" + 0.035*\"city\" + 0.034*\"mortgage\" + 0.030*\"household\" + '\n",
      "  '0.025*\"cool\" + 0.021*\"buyer\"'),\n",
      " (2,\n",
      "  '0.234*\"trade\" + 0.083*\"tariff\" + 0.073*\"chinese\" + 0.045*\"good\" + '\n",
      "  '0.030*\"import\" + 0.028*\"export\" + 0.028*\"war\" + 0.024*\"talk\" + '\n",
      "  '0.023*\"global\" + 0.021*\"deal\"'),\n",
      " (3,\n",
      "  '0.044*\"digital\" + 0.040*\"insurance\" + 0.037*\"technology\" + 0.033*\"consumer\" '\n",
      "  '+ 0.032*\"customer\" + 0.028*\"tech\" + 0.026*\"service\" + 0.024*\"network\" + '\n",
      "  '0.022*\"payment\" + 0.022*\"use\"'),\n",
      " (4,\n",
      "  '0.145*\"food\" + 0.082*\"italian\" + 0.055*\"season\" + 0.053*\"item\" + '\n",
      "  '0.044*\"hotel\" + 0.041*\"black\" + 0.038*\"restaurant\" + 0.035*\"climate_change\" '\n",
      "  '+ 0.029*\"collection\" + 0.028*\"chip\"'),\n",
      " (5,\n",
      "  '0.079*\"company\" + 0.031*\"business\" + 0.025*\"firm\" + 0.022*\"industry\" + '\n",
      "  '0.021*\"say\" + 0.015*\"accord\" + 0.012*\"car\" + 0.012*\"purchase\" + '\n",
      "  '0.012*\"sale\" + 0.012*\"cost\"'),\n",
      " (6,\n",
      "  '0.039*\"bank\" + 0.039*\"say\" + 0.036*\"financial\" + 0.019*\"system\" + '\n",
      "  '0.019*\"case\" + 0.018*\"rule\" + 0.012*\"risk\" + 0.012*\"report\" + '\n",
      "  '0.010*\"banking\" + 0.010*\"review\"'),\n",
      " (7,\n",
      "  '0.052*\"market\" + 0.024*\"global\" + 0.022*\"year\" + 0.020*\"high\" + 0.015*\"low\" '\n",
      "  '+ 0.012*\"risk\" + 0.012*\"financial\" + 0.012*\"hit\" + 0.011*\"currency\" + '\n",
      "  '0.011*\"dollar\"'),\n",
      " (8,\n",
      "  '0.058*\"report\" + 0.041*\"week\" + 0.033*\"datum\" + 0.028*\"stock\" + '\n",
      "  '0.022*\"point\" + 0.021*\"day\" + 0.020*\"expect\" + 0.018*\"due\" + 0.018*\"trade\" '\n",
      "  '+ 0.015*\"oil\"'),\n",
      " (9,\n",
      "  '0.061*\"growth\" + 0.058*\"year\" + 0.046*\"economy\" + 0.031*\"say\" + '\n",
      "  '0.025*\"economic\" + 0.025*\"expect\" + 0.018*\"quarter\" + 0.017*\"economist\" + '\n",
      "  '0.016*\"month\" + 0.015*\"forecast\"'),\n",
      " (10,\n",
      "  '0.076*\"job\" + 0.067*\"labor\" + 0.061*\"worker\" + 0.034*\"wage\" + 0.031*\"pay\" + '\n",
      "  '0.028*\"work\" + 0.022*\"unemployment\" + 0.021*\"income\" + 0.020*\"low\" + '\n",
      "  '0.017*\"high\"'),\n",
      " (11,\n",
      "  '0.094*\"tax\" + 0.076*\"government\" + 0.066*\"fiscal\" + 0.062*\"budget\" + '\n",
      "  '0.034*\"spending\" + 0.030*\"deficit\" + 0.027*\"year\" + 0.022*\"debt\" + '\n",
      "  '0.021*\"cut\" + 0.020*\"plan\"'),\n",
      " (12,\n",
      "  '0.079*\"school\" + 0.065*\"wealth\" + 0.054*\"woman\" + 0.054*\"family\" + '\n",
      "  '0.048*\"death\" + 0.038*\"die\" + 0.035*\"student\" + 0.030*\"child\" + '\n",
      "  '0.029*\"mechanism\" + 0.024*\"live\"'),\n",
      " (13,\n",
      "  '0.063*\"debt\" + 0.057*\"bond\" + 0.048*\"fund\" + 0.044*\"bank\" + 0.033*\"loan\" + '\n",
      "  '0.025*\"year\" + 0.020*\"reserve\" + 0.020*\"cash\" + 0.020*\"money\" + '\n",
      "  '0.018*\"investor\"'),\n",
      " (14,\n",
      "  '0.148*\"oil\" + 0.134*\"sanction\" + 0.113*\"protest\" + 0.080*\"military\" + '\n",
      "  '0.047*\"russian\" + 0.035*\"western\" + 0.026*\"violence\" + 0.024*\"rethink\" + '\n",
      "  '0.018*\"gas\" + 0.016*\"impose\"'),\n",
      " (15,\n",
      "  '0.074*\"travel\" + 0.060*\"kill\" + 0.047*\"flight\" + 0.044*\"repo\" + '\n",
      "  '0.044*\"airline\" + 0.043*\"death\" + 0.038*\"passenger\" + 0.033*\"attack\" + '\n",
      "  '0.025*\"indian\" + 0.023*\"quote\"'),\n",
      " (16,\n",
      "  '0.039*\"price\" + 0.038*\"farm\" + 0.037*\"farmer\" + 0.035*\"subsidy\" + '\n",
      "  '0.034*\"energy\" + 0.028*\"production\" + 0.027*\"plant\" + 0.026*\"capacity\" + '\n",
      "  '0.025*\"climate\" + 0.024*\"agricultural\"'),\n",
      " (17,\n",
      "  '0.045*\"say\" + 0.043*\"country\" + 0.039*\"investment\" + 0.035*\"government\" + '\n",
      "  '0.027*\"foreign\" + 0.021*\"economic\" + 0.020*\"sector\" + 0.017*\"chinese\" + '\n",
      "  '0.017*\"economy\" + 0.016*\"state\"'),\n",
      " (18,\n",
      "  '0.064*\"say\" + 0.027*\"would\" + 0.019*\"deal\" + 0.014*\"government\" + '\n",
      "  '0.014*\"official\" + 0.010*\"week\" + 0.010*\"country\" + 0.009*\"could\" + '\n",
      "  '0.009*\"tell\" + 0.008*\"also\"'),\n",
      " (19,\n",
      "  '0.109*\"rate\" + 0.057*\"policy\" + 0.044*\"inflation\" + 0.034*\"bank\" + '\n",
      "  '0.034*\"cut\" + 0.032*\"interest\" + 0.025*\"central\" + 0.025*\"monetary\" + '\n",
      "  '0.020*\"say\" + 0.016*\"target\"')]\n"
     ]
    }
   ],
   "source": [
    "# lda 모델의 토픽보기 \n",
    "# 토픽별 10개 키워드 \n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -10.007470477905306\n"
     ]
    }
   ],
   "source": [
    "# 모델 난이도와 일관성 점수 계산 \n",
    "print('\\nPerplexity: ',lda_model.log_perplexity(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.45391983449464923\n"
     ]
    }
   ],
   "source": [
    "coherence_model_lda = CoherenceModel(model = lda_model, texts = train_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ',coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0.039064944),\n",
       "  (1, 0.23853052),\n",
       "  (7, 0.22616611),\n",
       "  (8, 0.039323464),\n",
       "  (9, 0.25449947),\n",
       "  (11, 0.03941763),\n",
       "  (17, 0.05663374),\n",
       "  (18, 0.032787155),\n",
       "  (19, 0.060852256)],\n",
       " [(0, 0.1376976),\n",
       "  (1, 0.025801694),\n",
       "  (5, 0.07948344),\n",
       "  (6, 0.10837357),\n",
       "  (9, 0.046786692),\n",
       "  (10, 0.029014887),\n",
       "  (13, 0.30924252),\n",
       "  (16, 0.038003113),\n",
       "  (17, 0.06468784),\n",
       "  (18, 0.11934305),\n",
       "  (19, 0.028400019)],\n",
       " [(0, 0.041109044),\n",
       "  (5, 0.011147422),\n",
       "  (7, 0.1579221),\n",
       "  (9, 0.110561796),\n",
       "  (17, 0.05226727),\n",
       "  (18, 0.22173339),\n",
       "  (19, 0.37446195)],\n",
       " [(0, 0.18398969),\n",
       "  (1, 0.036000546),\n",
       "  (2, 0.010855934),\n",
       "  (3, 0.2113515),\n",
       "  (5, 0.11228948),\n",
       "  (6, 0.21998909),\n",
       "  (7, 0.10612155),\n",
       "  (8, 0.04930143),\n",
       "  (18, 0.041730665)],\n",
       " [(0, 0.12479729),\n",
       "  (2, 0.010040674),\n",
       "  (5, 0.0828783),\n",
       "  (7, 0.098115675),\n",
       "  (8, 0.057910703),\n",
       "  (9, 0.12229714),\n",
       "  (10, 0.04566448),\n",
       "  (15, 0.01264076),\n",
       "  (17, 0.3470738),\n",
       "  (18, 0.067172185),\n",
       "  (19, 0.016773101)],\n",
       " [(0, 0.17908257),\n",
       "  (2, 0.03192796),\n",
       "  (5, 0.06300078),\n",
       "  (6, 0.02053964),\n",
       "  (7, 0.23002866),\n",
       "  (9, 0.13214967),\n",
       "  (11, 0.01730395),\n",
       "  (13, 0.0101804985),\n",
       "  (16, 0.24207287),\n",
       "  (18, 0.058923583)],\n",
       " [(0, 0.046228673),\n",
       "  (7, 0.2756465),\n",
       "  (9, 0.06846718),\n",
       "  (13, 0.032119825),\n",
       "  (17, 0.046697732),\n",
       "  (18, 0.2786478),\n",
       "  (19, 0.21881509)],\n",
       " [(0, 0.358577),\n",
       "  (1, 0.14270505),\n",
       "  (3, 0.015145243),\n",
       "  (5, 0.041026283),\n",
       "  (6, 0.12878025),\n",
       "  (7, 0.07451265),\n",
       "  (8, 0.018654203),\n",
       "  (9, 0.028905835),\n",
       "  (13, 0.08118052),\n",
       "  (18, 0.08387107),\n",
       "  (19, 0.014792177)],\n",
       " [(0, 0.27135655),\n",
       "  (7, 0.12908746),\n",
       "  (9, 0.1459824),\n",
       "  (10, 0.036939573),\n",
       "  (18, 0.09092717),\n",
       "  (19, 0.30386984)],\n",
       " [(0, 0.053613514),\n",
       "  (5, 0.04166242),\n",
       "  (6, 0.020987045),\n",
       "  (7, 0.29232368),\n",
       "  (8, 0.07646761),\n",
       "  (9, 0.14822984),\n",
       "  (12, 0.019967321),\n",
       "  (15, 0.010338621),\n",
       "  (17, 0.2685094),\n",
       "  (18, 0.04161922),\n",
       "  (19, 0.016315715)]]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr = [lda_model.get_document_topics(c) for c in corpus[:10]]\n",
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpd = pd.concat([pd.DataFrame(t).assign(idx=i) for i,t in enumerate(tpr)])\n",
    "tpd = tpd.pivot(index='idx',columns=0,values=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.039065</td>\n",
       "      <td>0.238531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226166</td>\n",
       "      <td>0.039323</td>\n",
       "      <td>0.254499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056634</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.060852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.137698</td>\n",
       "      <td>0.025802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079483</td>\n",
       "      <td>0.108374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046787</td>\n",
       "      <td>0.029015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.309243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038003</td>\n",
       "      <td>0.064688</td>\n",
       "      <td>0.119343</td>\n",
       "      <td>0.028400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.041109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052267</td>\n",
       "      <td>0.221733</td>\n",
       "      <td>0.374462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.183990</td>\n",
       "      <td>0.036001</td>\n",
       "      <td>0.010856</td>\n",
       "      <td>0.211351</td>\n",
       "      <td>0.112289</td>\n",
       "      <td>0.219989</td>\n",
       "      <td>0.106122</td>\n",
       "      <td>0.049301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041731</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.124797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098116</td>\n",
       "      <td>0.057911</td>\n",
       "      <td>0.122297</td>\n",
       "      <td>0.045664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347074</td>\n",
       "      <td>0.067172</td>\n",
       "      <td>0.016773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0          0         1         2         3         5         6         7   \\\n",
       "idx                                                                         \n",
       "0    0.039065  0.238531  0.000000  0.000000  0.000000  0.000000  0.226166   \n",
       "1    0.137698  0.025802  0.000000  0.000000  0.079483  0.108374  0.000000   \n",
       "2    0.041109  0.000000  0.000000  0.000000  0.011147  0.000000  0.157922   \n",
       "3    0.183990  0.036001  0.010856  0.211351  0.112289  0.219989  0.106122   \n",
       "4    0.124797  0.000000  0.010041  0.000000  0.082878  0.000000  0.098116   \n",
       "\n",
       "0          8         9         10        11   12        13        15  \\\n",
       "idx                                                                    \n",
       "0    0.039323  0.254499  0.000000  0.039418  0.0  0.000000  0.000000   \n",
       "1    0.000000  0.046787  0.029015  0.000000  0.0  0.309243  0.000000   \n",
       "2    0.000000  0.110562  0.000000  0.000000  0.0  0.000000  0.000000   \n",
       "3    0.049301  0.000000  0.000000  0.000000  0.0  0.000000  0.000000   \n",
       "4    0.057911  0.122297  0.045664  0.000000  0.0  0.000000  0.012641   \n",
       "\n",
       "0          16        17        18        19  \n",
       "idx                                          \n",
       "0    0.000000  0.056634  0.032787  0.060852  \n",
       "1    0.038003  0.064688  0.119343  0.028400  \n",
       "2    0.000000  0.052267  0.221733  0.374462  \n",
       "3    0.000000  0.000000  0.041731  0.000000  \n",
       "4    0.000000  0.347074  0.067172  0.016773  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpd['sum'] = tpd.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.039065</td>\n",
       "      <td>0.238531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226166</td>\n",
       "      <td>0.039323</td>\n",
       "      <td>0.254499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056634</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.060852</td>\n",
       "      <td>0.987275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.137698</td>\n",
       "      <td>0.025802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079483</td>\n",
       "      <td>0.108374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046787</td>\n",
       "      <td>0.029015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.309243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038003</td>\n",
       "      <td>0.064688</td>\n",
       "      <td>0.119343</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.986834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.041109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052267</td>\n",
       "      <td>0.221733</td>\n",
       "      <td>0.374462</td>\n",
       "      <td>0.969203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.183990</td>\n",
       "      <td>0.036001</td>\n",
       "      <td>0.010856</td>\n",
       "      <td>0.211351</td>\n",
       "      <td>0.112289</td>\n",
       "      <td>0.219989</td>\n",
       "      <td>0.106122</td>\n",
       "      <td>0.049301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041731</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.971630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.124797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098116</td>\n",
       "      <td>0.057911</td>\n",
       "      <td>0.122297</td>\n",
       "      <td>0.045664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347074</td>\n",
       "      <td>0.067172</td>\n",
       "      <td>0.016773</td>\n",
       "      <td>0.985364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0           0         1         2         3         5         6         7  \\\n",
       "idx                                                                         \n",
       "0    0.039065  0.238531  0.000000  0.000000  0.000000  0.000000  0.226166   \n",
       "1    0.137698  0.025802  0.000000  0.000000  0.079483  0.108374  0.000000   \n",
       "2    0.041109  0.000000  0.000000  0.000000  0.011147  0.000000  0.157922   \n",
       "3    0.183990  0.036001  0.010856  0.211351  0.112289  0.219989  0.106122   \n",
       "4    0.124797  0.000000  0.010041  0.000000  0.082878  0.000000  0.098116   \n",
       "\n",
       "0           8         9        10        11   12        13        15  \\\n",
       "idx                                                                    \n",
       "0    0.039323  0.254499  0.000000  0.039418  0.0  0.000000  0.000000   \n",
       "1    0.000000  0.046787  0.029015  0.000000  0.0  0.309243  0.000000   \n",
       "2    0.000000  0.110562  0.000000  0.000000  0.0  0.000000  0.000000   \n",
       "3    0.049301  0.000000  0.000000  0.000000  0.0  0.000000  0.000000   \n",
       "4    0.057911  0.122297  0.045664  0.000000  0.0  0.000000  0.012641   \n",
       "\n",
       "0          16        17        18        19       sum  \n",
       "idx                                                    \n",
       "0    0.000000  0.056634  0.032787  0.060852  0.987275  \n",
       "1    0.038003  0.064688  0.119343  0.028400  0.986834  \n",
       "2    0.000000  0.052267  0.221733  0.374462  0.969203  \n",
       "3    0.000000  0.000000  0.041731  0.000000  0.971630  \n",
       "4    0.000000  0.347074  0.067172  0.016773  0.985364  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토픽-키워드 시각화\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coherence 점수로 적정 Topic 갯수 구하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(3,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coh_score = []\n",
    "for i in np.arange(3,21):\n",
    "    lda = gensim.models.ldamodel.LdaModel(corpus = corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=i,\n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "    coh_mod_ld = CoherenceModel(model = lda, texts = train_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "    coh_score.append(coh_mod_ld.get_coherence())\n",
    "    print('num_topics:',str(i),' done')\n",
    "coh = pd.DataFrame({'num_topics': np.arange(3,21), 'coherence':coh_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coh.style.background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('accord', 7),\n",
       "  ('ahead', 2),\n",
       "  ('also', 1),\n",
       "  ('area', 2),\n",
       "  ('available', 1),\n",
       "  ('average', 5),\n",
       "  ('back', 1),\n",
       "  ('bank', 1),\n",
       "  ('borrower', 1),\n",
       "  ('broaden', 1),\n",
       "  ('building', 1),\n",
       "  ('bumpy', 1),\n",
       "  ('business', 1),\n",
       "  ('cheapen', 1),\n",
       "  ('climb', 1),\n",
       "  ('com', 1),\n",
       "  ('compare', 3),\n",
       "  ('condo', 3),\n",
       "  ('construction', 1),\n",
       "  ('continue', 2),\n",
       "  ('cost', 1),\n",
       "  ('could', 2),\n",
       "  ('datum', 1),\n",
       "  ('decade', 1),\n",
       "  ('deflation', 1),\n",
       "  ('dormant', 1),\n",
       "  ('drown', 1),\n",
       "  ('earlier', 3),\n",
       "  ('early', 1),\n",
       "  ('economic', 1),\n",
       "  ('economy', 2),\n",
       "  ('effort', 1),\n",
       "  ('emerge', 1),\n",
       "  ('encourage', 1),\n",
       "  ('estimate', 1),\n",
       "  ('even', 1),\n",
       "  ('evidence', 1),\n",
       "  ('exist', 1),\n",
       "  ('expectation', 1),\n",
       "  ('fall', 3),\n",
       "  ('fifthly', 1),\n",
       "  ('financial', 1),\n",
       "  ('first', 1),\n",
       "  ('firstly', 1),\n",
       "  ('fiscal', 1),\n",
       "  ('fix', 1),\n",
       "  ('fortune', 1),\n",
       "  ('fourthly', 1),\n",
       "  ('global', 1),\n",
       "  ('goal', 1),\n",
       "  ('government', 1),\n",
       "  ('grow', 5),\n",
       "  ('guide', 1),\n",
       "  ('high', 1),\n",
       "  ('hit', 1),\n",
       "  ('home', 2),\n",
       "  ('impact', 1),\n",
       "  ('include', 1),\n",
       "  ('increase', 3),\n",
       "  ('index', 1),\n",
       "  ('inflation', 1),\n",
       "  ('information', 1),\n",
       "  ('infrastructure', 1),\n",
       "  ('institute', 1),\n",
       "  ('interest', 1),\n",
       "  ('invest', 1),\n",
       "  ('japan', 1),\n",
       "  ('japanese', 1),\n",
       "  ('land', 2),\n",
       "  ('large', 1),\n",
       "  ('last', 6),\n",
       "  ('late', 1),\n",
       "  ('level', 1),\n",
       "  ('loan', 1),\n",
       "  ('long', 2),\n",
       "  ('lower', 1),\n",
       "  ('major', 2),\n",
       "  ('mark', 1),\n",
       "  ('market', 3),\n",
       "  ('may', 4),\n",
       "  ('monetary', 1),\n",
       "  ('money', 1),\n",
       "  ('mortgage', 1),\n",
       "  ('motivate', 1),\n",
       "  ('nation', 1),\n",
       "  ('nearly', 1),\n",
       "  ('negative', 2),\n",
       "  ('new', 4),\n",
       "  ('number', 1),\n",
       "  ('offset', 1),\n",
       "  ('overall', 1),\n",
       "  ('overdue', 1),\n",
       "  ('pace', 1),\n",
       "  ('package', 1),\n",
       "  ('pay', 1),\n",
       "  ('peak', 2),\n",
       "  ('percent', 11),\n",
       "  ('period', 4),\n",
       "  ('plan', 1),\n",
       "  ('policy', 1),\n",
       "  ('potential', 1),\n",
       "  ('precrisis', 1),\n",
       "  ('prepare', 1),\n",
       "  ('price', 13),\n",
       "  ('property', 3),\n",
       "  ('raise', 1),\n",
       "  ('rate', 3),\n",
       "  ('rebound', 1),\n",
       "  ('recovery', 1),\n",
       "  ('release', 1),\n",
       "  ('report', 1),\n",
       "  ('resale', 1),\n",
       "  ('residential', 1),\n",
       "  ('rise', 4),\n",
       "  ('road', 1),\n",
       "  ('sale', 5),\n",
       "  ('say', 2),\n",
       "  ('secondly', 1),\n",
       "  ('sector', 1),\n",
       "  ('see', 2),\n",
       "  ('slow', 1),\n",
       "  ('stable', 1),\n",
       "  ('still', 3),\n",
       "  ('stimulate', 1),\n",
       "  ('stimulus', 1),\n",
       "  ('succeed', 1),\n",
       "  ('summer', 1),\n",
       "  ('surround', 1),\n",
       "  ('survey', 1),\n",
       "  ('swallow', 1),\n",
       "  ('take', 1),\n",
       "  ('tax', 4),\n",
       "  ('third', 1),\n",
       "  ('thirdly', 1),\n",
       "  ('thus', 1),\n",
       "  ('tourism', 1),\n",
       "  ('transport', 1),\n",
       "  ('trend', 1),\n",
       "  ('turnaround', 2),\n",
       "  ('upgrade', 1),\n",
       "  ('urban', 1),\n",
       "  ('value', 1),\n",
       "  ('various', 1),\n",
       "  ('wealth', 1),\n",
       "  ('week', 2),\n",
       "  ('world', 1),\n",
       "  ('year', 7),\n",
       "  ('yen', 1)]]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토픽 모델 만들기 \n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus = corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20,\n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.044*\"say\" + 0.014*\"year\" + 0.014*\"go\" + 0.013*\"make\" + 0.012*\"people\" + '\n",
      "  '0.012*\"would\" + 0.011*\"time\" + 0.011*\"take\" + 0.010*\"could\" + 0.010*\"get\"'),\n",
      " (1,\n",
      "  '0.076*\"home\" + 0.057*\"price\" + 0.055*\"housing\" + 0.043*\"property\" + '\n",
      "  '0.039*\"sale\" + 0.035*\"city\" + 0.034*\"mortgage\" + 0.030*\"household\" + '\n",
      "  '0.025*\"cool\" + 0.021*\"buyer\"'),\n",
      " (2,\n",
      "  '0.234*\"trade\" + 0.083*\"tariff\" + 0.073*\"chinese\" + 0.045*\"good\" + '\n",
      "  '0.030*\"import\" + 0.028*\"export\" + 0.028*\"war\" + 0.024*\"talk\" + '\n",
      "  '0.023*\"global\" + 0.021*\"deal\"'),\n",
      " (3,\n",
      "  '0.044*\"digital\" + 0.040*\"insurance\" + 0.037*\"technology\" + 0.033*\"consumer\" '\n",
      "  '+ 0.032*\"customer\" + 0.028*\"tech\" + 0.026*\"service\" + 0.024*\"network\" + '\n",
      "  '0.022*\"payment\" + 0.022*\"use\"'),\n",
      " (4,\n",
      "  '0.145*\"food\" + 0.082*\"italian\" + 0.055*\"season\" + 0.053*\"item\" + '\n",
      "  '0.044*\"hotel\" + 0.041*\"black\" + 0.038*\"restaurant\" + 0.035*\"climate_change\" '\n",
      "  '+ 0.029*\"collection\" + 0.028*\"chip\"'),\n",
      " (5,\n",
      "  '0.079*\"company\" + 0.031*\"business\" + 0.025*\"firm\" + 0.022*\"industry\" + '\n",
      "  '0.021*\"say\" + 0.015*\"accord\" + 0.012*\"car\" + 0.012*\"purchase\" + '\n",
      "  '0.012*\"sale\" + 0.012*\"cost\"'),\n",
      " (6,\n",
      "  '0.039*\"bank\" + 0.039*\"say\" + 0.036*\"financial\" + 0.019*\"system\" + '\n",
      "  '0.019*\"case\" + 0.018*\"rule\" + 0.012*\"risk\" + 0.012*\"report\" + '\n",
      "  '0.010*\"banking\" + 0.010*\"review\"'),\n",
      " (7,\n",
      "  '0.052*\"market\" + 0.024*\"global\" + 0.022*\"year\" + 0.020*\"high\" + 0.015*\"low\" '\n",
      "  '+ 0.012*\"risk\" + 0.012*\"financial\" + 0.012*\"hit\" + 0.011*\"currency\" + '\n",
      "  '0.011*\"dollar\"'),\n",
      " (8,\n",
      "  '0.058*\"report\" + 0.041*\"week\" + 0.033*\"datum\" + 0.028*\"stock\" + '\n",
      "  '0.022*\"point\" + 0.021*\"day\" + 0.020*\"expect\" + 0.018*\"due\" + 0.018*\"trade\" '\n",
      "  '+ 0.015*\"oil\"'),\n",
      " (9,\n",
      "  '0.061*\"growth\" + 0.058*\"year\" + 0.046*\"economy\" + 0.031*\"say\" + '\n",
      "  '0.025*\"economic\" + 0.025*\"expect\" + 0.018*\"quarter\" + 0.017*\"economist\" + '\n",
      "  '0.016*\"month\" + 0.015*\"forecast\"'),\n",
      " (10,\n",
      "  '0.076*\"job\" + 0.067*\"labor\" + 0.061*\"worker\" + 0.034*\"wage\" + 0.031*\"pay\" + '\n",
      "  '0.028*\"work\" + 0.022*\"unemployment\" + 0.021*\"income\" + 0.020*\"low\" + '\n",
      "  '0.017*\"high\"'),\n",
      " (11,\n",
      "  '0.094*\"tax\" + 0.076*\"government\" + 0.066*\"fiscal\" + 0.062*\"budget\" + '\n",
      "  '0.034*\"spending\" + 0.030*\"deficit\" + 0.027*\"year\" + 0.022*\"debt\" + '\n",
      "  '0.021*\"cut\" + 0.020*\"plan\"'),\n",
      " (12,\n",
      "  '0.079*\"school\" + 0.065*\"wealth\" + 0.054*\"woman\" + 0.054*\"family\" + '\n",
      "  '0.048*\"death\" + 0.038*\"die\" + 0.035*\"student\" + 0.030*\"child\" + '\n",
      "  '0.029*\"mechanism\" + 0.024*\"live\"'),\n",
      " (13,\n",
      "  '0.063*\"debt\" + 0.057*\"bond\" + 0.048*\"fund\" + 0.044*\"bank\" + 0.033*\"loan\" + '\n",
      "  '0.025*\"year\" + 0.020*\"reserve\" + 0.020*\"cash\" + 0.020*\"money\" + '\n",
      "  '0.018*\"investor\"'),\n",
      " (14,\n",
      "  '0.148*\"oil\" + 0.134*\"sanction\" + 0.113*\"protest\" + 0.080*\"military\" + '\n",
      "  '0.047*\"russian\" + 0.035*\"western\" + 0.026*\"violence\" + 0.024*\"rethink\" + '\n",
      "  '0.018*\"gas\" + 0.016*\"impose\"'),\n",
      " (15,\n",
      "  '0.074*\"travel\" + 0.060*\"kill\" + 0.047*\"flight\" + 0.044*\"repo\" + '\n",
      "  '0.044*\"airline\" + 0.043*\"death\" + 0.038*\"passenger\" + 0.033*\"attack\" + '\n",
      "  '0.025*\"indian\" + 0.023*\"quote\"'),\n",
      " (16,\n",
      "  '0.039*\"price\" + 0.038*\"farm\" + 0.037*\"farmer\" + 0.035*\"subsidy\" + '\n",
      "  '0.034*\"energy\" + 0.028*\"production\" + 0.027*\"plant\" + 0.026*\"capacity\" + '\n",
      "  '0.025*\"climate\" + 0.024*\"agricultural\"'),\n",
      " (17,\n",
      "  '0.045*\"say\" + 0.043*\"country\" + 0.039*\"investment\" + 0.035*\"government\" + '\n",
      "  '0.027*\"foreign\" + 0.021*\"economic\" + 0.020*\"sector\" + 0.017*\"chinese\" + '\n",
      "  '0.017*\"economy\" + 0.016*\"state\"'),\n",
      " (18,\n",
      "  '0.064*\"say\" + 0.027*\"would\" + 0.019*\"deal\" + 0.014*\"government\" + '\n",
      "  '0.014*\"official\" + 0.010*\"week\" + 0.010*\"country\" + 0.009*\"could\" + '\n",
      "  '0.009*\"tell\" + 0.008*\"also\"'),\n",
      " (19,\n",
      "  '0.109*\"rate\" + 0.057*\"policy\" + 0.044*\"inflation\" + 0.034*\"bank\" + '\n",
      "  '0.034*\"cut\" + 0.032*\"interest\" + 0.025*\"central\" + 0.025*\"monetary\" + '\n",
      "  '0.020*\"say\" + 0.016*\"target\"')]\n"
     ]
    }
   ],
   "source": [
    "# lda 모델의 토픽보기 \n",
    "# 토픽별 10개 키워드 \n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -10.007470477905306\n"
     ]
    }
   ],
   "source": [
    "# 모델 난이도와 일관성 점수 계산 \n",
    "print('\\nPerplexity: ',lda_model.log_perplexity(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.45391983449464923\n"
     ]
    }
   ],
   "source": [
    "coherence_model_lda = CoherenceModel(model = lda_model, texts = train_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ',coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0.039064944),\n",
       "  (1, 0.23853052),\n",
       "  (7, 0.22616611),\n",
       "  (8, 0.039323464),\n",
       "  (9, 0.25449947),\n",
       "  (11, 0.03941763),\n",
       "  (17, 0.05663374),\n",
       "  (18, 0.032787155),\n",
       "  (19, 0.060852256)],\n",
       " [(0, 0.1376976),\n",
       "  (1, 0.025801694),\n",
       "  (5, 0.07948344),\n",
       "  (6, 0.10837357),\n",
       "  (9, 0.046786692),\n",
       "  (10, 0.029014887),\n",
       "  (13, 0.30924252),\n",
       "  (16, 0.038003113),\n",
       "  (17, 0.06468784),\n",
       "  (18, 0.11934305),\n",
       "  (19, 0.028400019)],\n",
       " [(0, 0.041109044),\n",
       "  (5, 0.011147422),\n",
       "  (7, 0.1579221),\n",
       "  (9, 0.110561796),\n",
       "  (17, 0.05226727),\n",
       "  (18, 0.22173339),\n",
       "  (19, 0.37446195)],\n",
       " [(0, 0.18398969),\n",
       "  (1, 0.036000546),\n",
       "  (2, 0.010855934),\n",
       "  (3, 0.2113515),\n",
       "  (5, 0.11228948),\n",
       "  (6, 0.21998909),\n",
       "  (7, 0.10612155),\n",
       "  (8, 0.04930143),\n",
       "  (18, 0.041730665)],\n",
       " [(0, 0.12479729),\n",
       "  (2, 0.010040674),\n",
       "  (5, 0.0828783),\n",
       "  (7, 0.098115675),\n",
       "  (8, 0.057910703),\n",
       "  (9, 0.12229714),\n",
       "  (10, 0.04566448),\n",
       "  (15, 0.01264076),\n",
       "  (17, 0.3470738),\n",
       "  (18, 0.067172185),\n",
       "  (19, 0.016773101)],\n",
       " [(0, 0.17908257),\n",
       "  (2, 0.03192796),\n",
       "  (5, 0.06300078),\n",
       "  (6, 0.02053964),\n",
       "  (7, 0.23002866),\n",
       "  (9, 0.13214967),\n",
       "  (11, 0.01730395),\n",
       "  (13, 0.0101804985),\n",
       "  (16, 0.24207287),\n",
       "  (18, 0.058923583)],\n",
       " [(0, 0.046228673),\n",
       "  (7, 0.2756465),\n",
       "  (9, 0.06846718),\n",
       "  (13, 0.032119825),\n",
       "  (17, 0.046697732),\n",
       "  (18, 0.2786478),\n",
       "  (19, 0.21881509)],\n",
       " [(0, 0.358577),\n",
       "  (1, 0.14270505),\n",
       "  (3, 0.015145243),\n",
       "  (5, 0.041026283),\n",
       "  (6, 0.12878025),\n",
       "  (7, 0.07451265),\n",
       "  (8, 0.018654203),\n",
       "  (9, 0.028905835),\n",
       "  (13, 0.08118052),\n",
       "  (18, 0.08387107),\n",
       "  (19, 0.014792177)],\n",
       " [(0, 0.27135655),\n",
       "  (7, 0.12908746),\n",
       "  (9, 0.1459824),\n",
       "  (10, 0.036939573),\n",
       "  (18, 0.09092717),\n",
       "  (19, 0.30386984)],\n",
       " [(0, 0.053613514),\n",
       "  (5, 0.04166242),\n",
       "  (6, 0.020987045),\n",
       "  (7, 0.29232368),\n",
       "  (8, 0.07646761),\n",
       "  (9, 0.14822984),\n",
       "  (12, 0.019967321),\n",
       "  (15, 0.010338621),\n",
       "  (17, 0.2685094),\n",
       "  (18, 0.04161922),\n",
       "  (19, 0.016315715)]]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr = [lda_model.get_document_topics(c) for c in corpus[:10]]\n",
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpd = pd.concat([pd.DataFrame(t).assign(idx=i) for i,t in enumerate(tpr)])\n",
    "tpd = tpd.pivot(index='idx',columns=0,values=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.039065</td>\n",
       "      <td>0.238531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226166</td>\n",
       "      <td>0.039323</td>\n",
       "      <td>0.254499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056634</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.060852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.137698</td>\n",
       "      <td>0.025802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079483</td>\n",
       "      <td>0.108374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046787</td>\n",
       "      <td>0.029015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.309243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038003</td>\n",
       "      <td>0.064688</td>\n",
       "      <td>0.119343</td>\n",
       "      <td>0.028400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.041109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052267</td>\n",
       "      <td>0.221733</td>\n",
       "      <td>0.374462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.183990</td>\n",
       "      <td>0.036001</td>\n",
       "      <td>0.010856</td>\n",
       "      <td>0.211351</td>\n",
       "      <td>0.112289</td>\n",
       "      <td>0.219989</td>\n",
       "      <td>0.106122</td>\n",
       "      <td>0.049301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041731</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.124797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098116</td>\n",
       "      <td>0.057911</td>\n",
       "      <td>0.122297</td>\n",
       "      <td>0.045664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347074</td>\n",
       "      <td>0.067172</td>\n",
       "      <td>0.016773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0          0         1         2         3         5         6         7   \\\n",
       "idx                                                                         \n",
       "0    0.039065  0.238531  0.000000  0.000000  0.000000  0.000000  0.226166   \n",
       "1    0.137698  0.025802  0.000000  0.000000  0.079483  0.108374  0.000000   \n",
       "2    0.041109  0.000000  0.000000  0.000000  0.011147  0.000000  0.157922   \n",
       "3    0.183990  0.036001  0.010856  0.211351  0.112289  0.219989  0.106122   \n",
       "4    0.124797  0.000000  0.010041  0.000000  0.082878  0.000000  0.098116   \n",
       "\n",
       "0          8         9         10        11   12        13        15  \\\n",
       "idx                                                                    \n",
       "0    0.039323  0.254499  0.000000  0.039418  0.0  0.000000  0.000000   \n",
       "1    0.000000  0.046787  0.029015  0.000000  0.0  0.309243  0.000000   \n",
       "2    0.000000  0.110562  0.000000  0.000000  0.0  0.000000  0.000000   \n",
       "3    0.049301  0.000000  0.000000  0.000000  0.0  0.000000  0.000000   \n",
       "4    0.057911  0.122297  0.045664  0.000000  0.0  0.000000  0.012641   \n",
       "\n",
       "0          16        17        18        19  \n",
       "idx                                          \n",
       "0    0.000000  0.056634  0.032787  0.060852  \n",
       "1    0.038003  0.064688  0.119343  0.028400  \n",
       "2    0.000000  0.052267  0.221733  0.374462  \n",
       "3    0.000000  0.000000  0.041731  0.000000  \n",
       "4    0.000000  0.347074  0.067172  0.016773  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpd['sum'] = tpd.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.039065</td>\n",
       "      <td>0.238531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226166</td>\n",
       "      <td>0.039323</td>\n",
       "      <td>0.254499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056634</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.060852</td>\n",
       "      <td>0.987275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.137698</td>\n",
       "      <td>0.025802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079483</td>\n",
       "      <td>0.108374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046787</td>\n",
       "      <td>0.029015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.309243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038003</td>\n",
       "      <td>0.064688</td>\n",
       "      <td>0.119343</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.986834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.041109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052267</td>\n",
       "      <td>0.221733</td>\n",
       "      <td>0.374462</td>\n",
       "      <td>0.969203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.183990</td>\n",
       "      <td>0.036001</td>\n",
       "      <td>0.010856</td>\n",
       "      <td>0.211351</td>\n",
       "      <td>0.112289</td>\n",
       "      <td>0.219989</td>\n",
       "      <td>0.106122</td>\n",
       "      <td>0.049301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041731</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.971630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.124797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098116</td>\n",
       "      <td>0.057911</td>\n",
       "      <td>0.122297</td>\n",
       "      <td>0.045664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347074</td>\n",
       "      <td>0.067172</td>\n",
       "      <td>0.016773</td>\n",
       "      <td>0.985364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0           0         1         2         3         5         6         7  \\\n",
       "idx                                                                         \n",
       "0    0.039065  0.238531  0.000000  0.000000  0.000000  0.000000  0.226166   \n",
       "1    0.137698  0.025802  0.000000  0.000000  0.079483  0.108374  0.000000   \n",
       "2    0.041109  0.000000  0.000000  0.000000  0.011147  0.000000  0.157922   \n",
       "3    0.183990  0.036001  0.010856  0.211351  0.112289  0.219989  0.106122   \n",
       "4    0.124797  0.000000  0.010041  0.000000  0.082878  0.000000  0.098116   \n",
       "\n",
       "0           8         9        10        11   12        13        15  \\\n",
       "idx                                                                    \n",
       "0    0.039323  0.254499  0.000000  0.039418  0.0  0.000000  0.000000   \n",
       "1    0.000000  0.046787  0.029015  0.000000  0.0  0.309243  0.000000   \n",
       "2    0.000000  0.110562  0.000000  0.000000  0.0  0.000000  0.000000   \n",
       "3    0.049301  0.000000  0.000000  0.000000  0.0  0.000000  0.000000   \n",
       "4    0.057911  0.122297  0.045664  0.000000  0.0  0.000000  0.012641   \n",
       "\n",
       "0          16        17        18        19       sum  \n",
       "idx                                                    \n",
       "0    0.000000  0.056634  0.032787  0.060852  0.987275  \n",
       "1    0.038003  0.064688  0.119343  0.028400  0.986834  \n",
       "2    0.000000  0.052267  0.221733  0.374462  0.969203  \n",
       "3    0.000000  0.000000  0.041731  0.000000  0.971630  \n",
       "4    0.000000  0.347074  0.067172  0.016773  0.985364  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토픽-키워드 시각화\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coherence 점수로 적정 Topic 갯수 구하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(3,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coh_score = []\n",
    "for i in np.arange(3,21):\n",
    "    lda = gensim.models.ldamodel.LdaModel(corpus = corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=i,\n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "    coh_mod_ld = CoherenceModel(model = lda, texts = train_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "    coh_score.append(coh_mod_ld.get_coherence())\n",
    "    print('num_topics:',str(i),' done')\n",
    "coh = pd.DataFrame({'num_topics': np.arange(3,21), 'coherence':coh_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coh.style.background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
